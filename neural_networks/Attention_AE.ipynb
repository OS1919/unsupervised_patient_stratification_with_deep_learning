{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8F5hak2ny1Ac","outputId":"da303bfb-fa1e-4974-b797-13dc22d87930","executionInfo":{"status":"ok","timestamp":1707912787721,"user_tz":-60,"elapsed":15822,"user":{"displayName":"CoSyBio","userId":"08929213564439946205"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.9/257.9 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-self-attention\n","  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention) (1.25.2)\n","Building wheels for collected packages: keras-self-attention\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=00122dc7acbc925ad65ccd2b6e5c83162233ff785969d01540e29bc13e735823\n","  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n","Successfully built keras-self-attention\n","Installing collected packages: keras-self-attention\n","Successfully installed keras-self-attention-0.51.0\n"]}],"source":["!pip install wandb -qU\n","!pip install keras-self-attention"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"QFZHwDJVoU6k","executionInfo":{"status":"ok","timestamp":1707912792603,"user_tz":-60,"elapsed":4898,"user":{"displayName":"CoSyBio","userId":"08929213564439946205"}}},"outputs":[],"source":["from keras.layers import Input, Dense, Flatten, Reshape\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras_self_attention import SeqSelfAttention\n","from keras.callbacks import EarlyStopping\n","\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score, davies_bouldin_score\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","\n","from google.colab import drive\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import os   # This module is used for interacting with the operating system. It provides a way to work with files and directories.\n","\n","import tensorflow as tf\n","import wandb\n","from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"id":"bOWepHd2y_4M","outputId":"d357b473-c7f9-4071-8a1a-f896400b26ba","executionInfo":{"status":"ok","timestamp":1707912803621,"user_tz":-60,"elapsed":11035,"user":{"displayName":"CoSyBio","userId":"08929213564439946205"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["wandb.login()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qbGm9tfxvaJw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"11b50f41-c7ff-411c-8bed-cb9402ff2a51","executionInfo":{"status":"ok","timestamp":1707912828339,"user_tz":-60,"elapsed":24751,"user":{"displayName":"CoSyBio","userId":"08929213564439946205"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Archive:  gdrive/MyDrive/TCGA-BRCA_1079.zip\n","  inflating: TCGA-BRCA_1079.Xena_TCGA_PanCan.annotation_v6.tsv  \n","  inflating: TCGA-BRCA_1079_17Kgenes.Xena_TCGA_PanCan.log2_exprs_z_v6.tsv  \n","  inflating: TCGA-BRCA_1079_17Kgenes.Xena_TCGA_PanCan.subtypes_and_signatures_v6.tsv  \n"]}],"source":["# --- Load data and setup directories ---\n","drive.mount('/content/gdrive')\n","!unzip gdrive/MyDrive/TCGA-BRCA_1079.zip\n","\n","#'r' before the string indicates a raw string ('\\' are treated as literal and not escape characters)\n","result_path = r\"results\"\n","\n","if not os.path.exists(result_path):\n","    os.makedirs(result_path)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"pRbszv4fzWEv","executionInfo":{"status":"ok","timestamp":1707912828340,"user_tz":-60,"elapsed":49,"user":{"displayName":"CoSyBio","userId":"08929213564439946205"}}},"outputs":[],"source":["class AE:\n","    def __init__(self,data,dims):\n","        self.data = data\n","        self.x, self.x_val = train_test_split(self.data, test_size=0.1, train_size=0.9)\n","\n","        self.input_dim = data.shape[1]\n","        self.encoding1_dim = dims[0]\n","        self.encoding2_dim = dims[1]\n","        self.encoding3_dim = dims[2]\n","        self.middle_dim = dims[3]\n","\n","        self.input_factor = Input(shape=(self.input_dim,))\n","        self.encoded = Dense(self.encoding1_dim, activation='sigmoid')(self.input_factor)\n","        self.encoded = Dense(self.encoding2_dim, activation='sigmoid')(self.encoded)\n","        self.encoded = Dense(self.encoding3_dim, activation='sigmoid')(self.encoded)\n","        self.encoded = Reshape((self.encoding3_dim, 1))(self.encoded) # Self-attention layer input needs to be a sequence\n","        self.encoded = SeqSelfAttention(attention_activation='linear')(self.encoded)\n","        self.encoded = Flatten()(self.encoded)\n","\n","        self.encoder_output = Dense(self.middle_dim, activation='sigmoid')(self.encoded)\n","\n","        self.decoded = Dense(self.encoding3_dim, activation='sigmoid')(self.encoder_output)\n","        self.decoded = Reshape((self.encoding3_dim, 1))(self.decoded)\n","        self.decoded = SeqSelfAttention(attention_activation='linear')(self.decoded)\n","        self.decoded = Flatten()(self.decoded)\n","        self.decoded = Dense(self.encoding2_dim, activation='sigmoid')(self.decoded)\n","        self.decoded = Dense(self.encoding1_dim, activation='sigmoid')(self.decoded)\n","        self.decoded = Dense(self.input_dim)(self.decoded)\n","\n","        self.autoencoder = Model(inputs=self.input_factor, outputs=self.decoded)\n","\n","        self.encoder = Model(inputs=self.input_factor, outputs=self.encoder_output)\n","\n","        # compile autoencoder\n","        # the initial learning rate for the 'adam' optimizer is 0.001\n","        custom_adam_optimizer = Adam(learning_rate=0.0005)\n","        self.autoencoder.compile(optimizer=custom_adam_optimizer, loss='mse')\n","\n","    def train(self):\n","        # This callback will log training and validation metrics along with system metrics to W&B\n","        callback_metrics = WandbMetricsLogger()\n","        early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=50, min_delta=0.01, restore_best_weights=True)\n","        self.autoencoder.fit(self.x, self.x, validation_data=(self.x_val, self.x_val), epochs=500, verbose=1, batch_size=32, shuffle=True, callbacks=[callback_metrics, early_stopping])\n","\n","    def save(self):\n","        self.autoencoder.save(\"./trained_model/model.h5\")\n","\n","    def predict(self,data):\n","        return self.encoder.predict(data)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"WO6gDuCCa8Na","colab":{"base_uri":"https://localhost:8080/"},"outputId":"460f8135-f2f6-486b-9eb5-5b374ce5d770","executionInfo":{"status":"ok","timestamp":1707912834159,"user_tz":-60,"elapsed":5859,"user":{"displayName":"CoSyBio","userId":"08929213564439946205"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of input data:  (17162, 1080)\n","[['A1BG' 0.1719444908272692 0.7300083449184781 ... 0.614468050540426\n","  1.3458846686508648 0.7186659277414379]\n"," ['A1CF' -0.814924951368837 2.386837959210663 ... 3.016626468680079\n","  -0.814924951368837 0.2356343444931301]\n"," ['A2M' -0.946474342215696 -0.5321448682087864 ... 0.5601782905367024\n","  1.512226893819039 -0.6446442624050204]\n"," ...\n"," ['DHCR7' 0.9104445032812696 0.3842357893348481 ... 0.7718469491250562\n","  -0.4217551872682497 -0.970509103357415]\n"," ['TMEM45B' -1.9635765960806173 1.268061022702539 ... -0.3477150909879061\n","  0.4043269887748967 -0.5444141861092432]\n"," ['GPR160' 0.6427457224400778 1.759067645972089 ... 0.3169998035848742\n","  -0.7956005603903231 -0.1338926768376846]]\n","Shape of prepared input data:  (1079, 17162)\n","[[0.1719444908272692 -0.814924951368837 -0.946474342215696 ...\n","  0.9104445032812696 -1.9635765960806173 0.6427457224400778]\n"," [0.7300083449184781 2.386837959210663 -0.5321448682087864 ...\n","  0.3842357893348481 1.268061022702539 1.759067645972089]\n"," [1.3131270906843395 1.4046621693192411 -0.5098647928040265 ...\n","  -0.7411763504136007 -1.8349771442669716 -0.4860543713706617]\n"," ...\n"," [0.614468050540426 3.016626468680079 0.5601782905367024 ...\n","  0.7718469491250562 -0.3477150909879061 0.3169998035848742]\n"," [1.3458846686508648 -0.814924951368837 1.512226893819039 ...\n","  -0.4217551872682497 0.4043269887748967 -0.7956005603903231]\n"," [0.7186659277414379 0.2356343444931301 -0.6446442624050204 ...\n","  -0.970509103357415 -0.5444141861092432 -0.1338926768376846]]\n","--- Converted to Float32 ---\n","[[ 0.17194448 -0.81492496 -0.9464743  ...  0.9104445  -1.9635766\n","   0.64274573]\n"," [ 0.73000836  2.386838   -0.53214484 ...  0.3842358   1.268061\n","   1.7590677 ]\n"," [ 1.313127    1.4046621  -0.5098648  ... -0.74117637 -1.8349771\n","  -0.48605436]\n"," ...\n"," [ 0.61446804  3.0166264   0.5601783  ...  0.77184695 -0.34771508\n","   0.3169998 ]\n"," [ 1.3458847  -0.81492496  1.5122269  ... -0.4217552   0.40432698\n","  -0.79560053]\n"," [ 0.71866596  0.23563434 -0.64464426 ... -0.9705091  -0.54441416\n","  -0.13389267]]\n"]}],"source":["# --- Prepare input data ---\n","input_data_frame = pd.read_csv(\"TCGA-BRCA_1079_17Kgenes.Xena_TCGA_PanCan.log2_exprs_z_v6.tsv\", sep=\"\\t\")   # read .tsv file into memory\n","input_data = input_data_frame.values  # retrieve values as numpy array\n","print (\"Shape of input data: \", input_data.shape) # rows are genes and columns are samples\n","print(input_data)\n","\n","input_data = np.transpose(input_data) # rows are samples and columns are genes\n","input_data = np.delete(input_data, (0), axis=0) # delete first row of the data matrix\n","print (\"Shape of prepared input data: \", input_data.shape)\n","print(input_data)\n","\n","input_data = np.asarray(input_data).astype(\"float32\") # Every character/number encoded with 32 Bit\n","print(\"--- Converted to Float32 ---\")\n","print(input_data)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"GEmBn-hU940R","colab":{"base_uri":"https://localhost:8080/"},"outputId":"731493d3-afb9-49bd-ed5c-e5d4beb4162c","executionInfo":{"status":"ok","timestamp":1707912834160,"user_tz":-60,"elapsed":49,"user":{"displayName":"CoSyBio","userId":"08929213564439946205"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of subtype labels:  (1079, 34)\n","[['TCGA-3C-AAAU-01' 'LumB' 0 ... 2 1 0]\n"," ['TCGA-3C-AALI-01' 'Her2' 0 ... 3 0 0]\n"," ['TCGA-3C-AALJ-01' 'LumB' 0 ... 3 0 0]\n"," ...\n"," ['TCGA-XX-A89A-01' 'LumA' 0 ... 1 0 0]\n"," ['TCGA-Z7-A8R5-01' 'LumA' 0 ... 1 0 0]\n"," ['TCGA-Z7-A8R6-01' 'LumB' 0 ... 3 0 0]]\n","{'Normal', 'LumA', 'Her2', 'LumB', 'Basal'}\n"]}],"source":["# --- Prepare labels ---\n","subtype_labels_frame = pd.read_csv(\"TCGA-BRCA_1079_17Kgenes.Xena_TCGA_PanCan.subtypes_and_signatures_v6.tsv\", sep=\"\\t\")\n","subtype_labels = subtype_labels_frame.values\n","print (\"Shape of subtype labels: \", subtype_labels.shape)\n","print(subtype_labels)\n","\n","subtype_label_set = set(subtype_labels[:,1])\n","print(subtype_label_set)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"E-w1E2vY0HK-","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4a5abe10049845a7af5a0cab3924b3a6","77fc5313a5c74e23ba996e56a16cd569","413218635fda425abd9973a4d2dd977e","1b2810cce0374abaa89c483b496d8326","74d50636d20e4a378f8fe2b82405b267","31b50d33ede04b688f7ef9cc06f79c99","d13c0f7a472540cdbe40a4e1e08fac54","64a11b7adc2149fd9624a929961f8c49","4f1ab337d4d94bd593921b689ff34bb7","67e0bcb2bf4c4f60b46a2895fd8bb742","d3a4e09cda804c979a5145b1c92ef98d","6496e450d7f34d0492232db68255f0d0","c83ad2d9536a4549ad62a5da4ca22d38","ba8fcc4e0e06471e994c3b77d6b2bff5","9404b0dd4c7844d8a15a84ba45838431","f394af8cb0d14e1a818d22f15e8f9677","69776819526d445dac35553c3d095d51","6e463566688b434082995cadbf07a9a1","8f183b0ec16f4cb9bd36161d872c5cf7","7909d9dc4755458293e15a8c0b75e40a","e12fcf51748c441481973edb5425a6ad","38b6d5ea99d047fb8aeb36a4327f74f0","2c5e076491784412963d74f86c24da1e","68610d8c1b364d9496a8a4bcf06c8a9a","2ddecf9b347647f99d4d52524d7dd9c9","52c14fec408142feb7e6dc85d3eded93","266e89f34b2541e096fc21dde118e9f0","8fa0affb3f24437f91168fd58ef7f44b","00f349b1a74e497998f4b73b4cf693cf","f04c1ab0d19743a284613e9db43acc98","ac8563cc8f4446a4b15083474d84e7e8","3c76f2c77ef24a3bbda2a12ed1d92fe0","4f7d78c6fba449838a29429bf5c865d8","880877a1923a4ff3ae91e27f4daf9ba7","984d149559b24aebad9e1ed2c2aa736c","b7a082541f1e4be6bce3acd4f3d5f07b","616ab1eb761d41ab8ecc79d80cebeb70","c8e66f1855ee4c06af20f81d641b817a","5951f5551a5942fb8023a9c4df946594","3b014897f2a44ced8559897a4c43edc5","fa62773373fa4ed18a5e1f758b2b14ca","a7d53d930163452d88b4fdacc9328f7f","05f34536f54244b7bce8bbe2a5a2b045","2cfc19e88a294b619e94582205a614d2","f15f77ca3b7b45f7aa57c50fae41f964","01bba803a0e24790b396dbe81044f906","dddc267f65fb4fc4ad0f17173a98fc89","cad5e43c42554a9c89ccc66efb8d2448","7a39ee3237ff4792b4de24211fe46f86","5ad675b27d17451d9233e8d1ba09fad2","833a9c94f65541a79f8f74d579863485","5c94aaf7663c41f7a37552341be63a98","b8c51aeb7d2d4876bbae835c3afb5216","0b8eb8bb5a6c436f947f999ceb53d984","4bf77b4ca2b945e7a222b34d402aee5d","18b856029c0848139973f21434f5f7a6","4693c213b33d4c20bc75a428211e7d75","f5eb938f552c4ac9b33765a19a70ebb4","dfafe3d53cff4c269ff29bb0eca68cce","61ec2ed81b064c628d4ea33b11088777","77d2897b14c74cb8b8888b3951cda99d","0712ee4c32c44edab77413b35f3d3f33","a022aafd441940e68806b49996f48eab","e22624203e26469fbdfcc7da446425d4"]},"outputId":"fc717a02-b72e-42d2-fbd1-93f07784531f","executionInfo":{"status":"ok","timestamp":1707913874389,"user_tz":-60,"elapsed":1040247,"user":{"displayName":"CoSyBio","userId":"08929213564439946205"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcosybio-compsysmed\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240214_121352-c1hrq7cy</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/c1hrq7cy' target=\"_blank\">early_stopping_patience_50</a></strong> to <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/c1hrq7cy' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/c1hrq7cy</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 17162)]           0         \n","                                                                 \n"," dense (Dense)               (None, 8000)              137304000 \n","                                                                 \n"," dense_1 (Dense)             (None, 1000)              8001000   \n","                                                                 \n"," dense_2 (Dense)             (None, 200)               200200    \n","                                                                 \n"," reshape (Reshape)           (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention (SeqSel  (None, 200, 1)            129       \n"," fAttention)                                                     \n","                                                                 \n"," flatten (Flatten)           (None, 200)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                2010      \n","                                                                 \n"," dense_4 (Dense)             (None, 200)               2200      \n","                                                                 \n"," reshape_1 (Reshape)         (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_1 (SeqS  (None, 200, 1)            129       \n"," elfAttention)                                                   \n","                                                                 \n"," flatten_1 (Flatten)         (None, 200)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 1000)              201000    \n","                                                                 \n"," dense_6 (Dense)             (None, 8000)              8008000   \n","                                                                 \n"," dense_7 (Dense)             (None, 17162)             137313162 \n","                                                                 \n","=================================================================\n","Total params: 291031830 (1.08 GB)\n","Trainable params: 291031830 (1.08 GB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/500\n"," 6/31 [====>.........................] - ETA: 0s - loss: 1.5005"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0108s vs `on_train_batch_end` time: 0.0118s). Check your callbacks.\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 10s 92ms/step - loss: 1.1147 - val_loss: 1.0352\n","Epoch 2/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9958 - val_loss: 1.0339\n","Epoch 3/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9955 - val_loss: 1.0339\n","Epoch 4/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9954 - val_loss: 1.0339\n","Epoch 5/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9954 - val_loss: 1.0340\n","Epoch 6/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9954 - val_loss: 1.0341\n","Epoch 7/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9953 - val_loss: 1.0341\n","Epoch 8/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9953 - val_loss: 1.0342\n","Epoch 9/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9953 - val_loss: 1.0343\n","Epoch 10/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9953 - val_loss: 1.0343\n","Epoch 11/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9953 - val_loss: 1.0345\n","Epoch 12/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9952 - val_loss: 1.0345\n","Epoch 13/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9952 - val_loss: 1.0346\n","Epoch 14/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9951 - val_loss: 1.0347\n","Epoch 15/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9951 - val_loss: 1.0347\n","Epoch 16/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9950 - val_loss: 1.0347\n","Epoch 17/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9949 - val_loss: 1.0348\n","Epoch 18/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9948 - val_loss: 1.0350\n","Epoch 19/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9946 - val_loss: 1.0351\n","Epoch 20/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9942 - val_loss: 1.0352\n","Epoch 21/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9935 - val_loss: 1.0350\n","Epoch 22/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9924 - val_loss: 1.0342\n","Epoch 23/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9910 - val_loss: 1.0333\n","Epoch 24/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9890 - val_loss: 1.0325\n","Epoch 25/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9870 - val_loss: 1.0292\n","Epoch 26/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9841 - val_loss: 1.0259\n","Epoch 27/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9808 - val_loss: 1.0236\n","Epoch 28/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9769 - val_loss: 1.0197\n","Epoch 29/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9734 - val_loss: 1.0165\n","Epoch 30/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9689 - val_loss: 1.0143\n","Epoch 31/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9656 - val_loss: 1.0102\n","Epoch 32/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9617 - val_loss: 1.0063\n","Epoch 33/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9583 - val_loss: 1.0047\n","Epoch 34/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9546 - val_loss: 1.0016\n","Epoch 35/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9511 - val_loss: 0.9989\n","Epoch 36/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9482 - val_loss: 0.9966\n","Epoch 37/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9455 - val_loss: 0.9952\n","Epoch 38/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9433 - val_loss: 0.9927\n","Epoch 39/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9409 - val_loss: 0.9910\n","Epoch 40/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9387 - val_loss: 0.9896\n","Epoch 41/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9369 - val_loss: 0.9879\n","Epoch 42/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9348 - val_loss: 0.9863\n","Epoch 43/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9332 - val_loss: 0.9851\n","Epoch 44/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9322 - val_loss: 0.9844\n","Epoch 45/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9309 - val_loss: 0.9831\n","Epoch 46/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9293 - val_loss: 0.9824\n","Epoch 47/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9281 - val_loss: 0.9808\n","Epoch 48/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9269 - val_loss: 0.9806\n","Epoch 49/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9255 - val_loss: 0.9791\n","Epoch 50/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9246 - val_loss: 0.9784\n","Epoch 51/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9236 - val_loss: 0.9788\n","Epoch 52/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9232 - val_loss: 0.9771\n","Epoch 53/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9220 - val_loss: 0.9759\n","Epoch 54/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9209 - val_loss: 0.9758\n","Epoch 55/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9202 - val_loss: 0.9745\n","Epoch 56/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9195 - val_loss: 0.9743\n","Epoch 57/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9186 - val_loss: 0.9735\n","Epoch 58/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9180 - val_loss: 0.9736\n","Epoch 59/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9172 - val_loss: 0.9733\n","Epoch 60/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9168 - val_loss: 0.9723\n","Epoch 61/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9161 - val_loss: 0.9714\n","Epoch 62/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9154 - val_loss: 0.9711\n","Epoch 63/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9148 - val_loss: 0.9710\n","Epoch 64/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9143 - val_loss: 0.9702\n","Epoch 65/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9138 - val_loss: 0.9703\n","Epoch 66/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9132 - val_loss: 0.9702\n","Epoch 67/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9129 - val_loss: 0.9684\n","Epoch 68/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9122 - val_loss: 0.9688\n","Epoch 69/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9118 - val_loss: 0.9685\n","Epoch 70/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9112 - val_loss: 0.9673\n","Epoch 71/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9109 - val_loss: 0.9675\n","Epoch 72/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9103 - val_loss: 0.9668\n","Epoch 73/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9100 - val_loss: 0.9664\n","Epoch 74/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9095 - val_loss: 0.9664\n","Epoch 75/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9092 - val_loss: 0.9661\n","Epoch 76/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9088 - val_loss: 0.9661\n","Epoch 77/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9087 - val_loss: 0.9656\n","Epoch 78/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9083 - val_loss: 0.9650\n","Epoch 79/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9078 - val_loss: 0.9653\n","Epoch 80/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9075 - val_loss: 0.9645\n","Epoch 81/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9073 - val_loss: 0.9640\n","Epoch 82/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9068 - val_loss: 0.9639\n","Epoch 83/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9066 - val_loss: 0.9633\n","Epoch 84/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9063 - val_loss: 0.9633\n","Epoch 85/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9061 - val_loss: 0.9644\n","Epoch 86/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9057 - val_loss: 0.9626\n","Epoch 87/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9055 - val_loss: 0.9624\n","Epoch 88/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9050 - val_loss: 0.9623\n","Epoch 89/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9047 - val_loss: 0.9615\n","Epoch 90/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9044 - val_loss: 0.9615\n","Epoch 91/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9042 - val_loss: 0.9609\n","Epoch 92/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9040 - val_loss: 0.9615\n","Epoch 93/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9037 - val_loss: 0.9611\n","Epoch 94/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9035 - val_loss: 0.9604\n","Epoch 95/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9033 - val_loss: 0.9613\n","Epoch 96/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9035 - val_loss: 0.9610\n","Epoch 97/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9032 - val_loss: 0.9613\n","Epoch 98/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9029 - val_loss: 0.9599\n","Epoch 99/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9025 - val_loss: 0.9599\n","Epoch 100/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9022 - val_loss: 0.9599\n","Epoch 101/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9020 - val_loss: 0.9597\n","Epoch 102/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9017 - val_loss: 0.9593\n","Epoch 103/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9014 - val_loss: 0.9592\n","Epoch 104/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9013 - val_loss: 0.9583\n","Epoch 105/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9011 - val_loss: 0.9583\n","Epoch 106/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9011 - val_loss: 0.9588\n","Epoch 107/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9010 - val_loss: 0.9586\n","Epoch 108/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9009 - val_loss: 0.9587\n","Epoch 109/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9004 - val_loss: 0.9579\n","Epoch 110/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9002 - val_loss: 0.9583\n","Epoch 111/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9001 - val_loss: 0.9582\n","Epoch 112/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9002 - val_loss: 0.9580\n","Epoch 113/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8996 - val_loss: 0.9583\n","Epoch 114/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8999 - val_loss: 0.9578\n","Epoch 115/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8997 - val_loss: 0.9574\n","Epoch 116/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8998 - val_loss: 0.9577\n","Epoch 117/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8995 - val_loss: 0.9574\n","Epoch 118/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8994 - val_loss: 0.9577\n","Epoch 119/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8990 - val_loss: 0.9578\n","Epoch 120/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8989 - val_loss: 0.9577\n","Epoch 121/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8986 - val_loss: 0.9569\n","Epoch 122/500\n","31/31 [==============================] - 2s 53ms/step - loss: 0.8986 - val_loss: 0.9568\n","34/34 [==============================] - 0s 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a5abe10049845a7af5a0cab3924b3a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▄▄▄▄▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>████████▇▇▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>121</td></tr><tr><td>epoch/learning_rate</td><td>0.0005</td></tr><tr><td>epoch/loss</td><td>0.89856</td></tr><tr><td>epoch/val_loss</td><td>0.95682</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">early_stopping_patience_50</strong> at: <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/c1hrq7cy' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/c1hrq7cy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240214_121352-c1hrq7cy/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240214_121546-wvfkrggd</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/wvfkrggd' target=\"_blank\">early_stopping_patience_50</a></strong> to <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/wvfkrggd' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/wvfkrggd</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 17162)]           0         \n","                                                                 \n"," dense_8 (Dense)             (None, 8000)              137304000 \n","                                                                 \n"," dense_9 (Dense)             (None, 1000)              8001000   \n","                                                                 \n"," dense_10 (Dense)            (None, 200)               200200    \n","                                                                 \n"," reshape_2 (Reshape)         (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_2 (SeqS  (None, 200, 1)            129       \n"," elfAttention)                                                   \n","                                                                 \n"," flatten_2 (Flatten)         (None, 200)               0         \n","                                                                 \n"," dense_11 (Dense)            (None, 10)                2010      \n","                                                                 \n"," dense_12 (Dense)            (None, 200)               2200      \n","                                                                 \n"," reshape_3 (Reshape)         (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_3 (SeqS  (None, 200, 1)            129       \n"," elfAttention)                                                   \n","                                                                 \n"," flatten_3 (Flatten)         (None, 200)               0         \n","                                                                 \n"," dense_13 (Dense)            (None, 1000)              201000    \n","                                                                 \n"," dense_14 (Dense)            (None, 8000)              8008000   \n","                                                                 \n"," dense_15 (Dense)            (None, 17162)             137313162 \n","                                                                 \n","=================================================================\n","Total params: 291031830 (1.08 GB)\n","Trainable params: 291031830 (1.08 GB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/500\n"," 6/31 [====>.........................] - ETA: 0s - loss: 1.5513"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0102s vs `on_train_batch_end` time: 0.0119s). Check your callbacks.\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 7s 82ms/step - loss: 1.1250 - val_loss: 0.9546\n","Epoch 2/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0047 - val_loss: 0.9535\n","Epoch 3/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0044 - val_loss: 0.9536\n","Epoch 4/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0043 - val_loss: 0.9536\n","Epoch 5/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0043 - val_loss: 0.9537\n","Epoch 6/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0043 - val_loss: 0.9538\n","Epoch 7/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0042 - val_loss: 0.9539\n","Epoch 8/500\n","31/31 [==============================] - 1s 26ms/step - loss: 1.0042 - val_loss: 0.9539\n","Epoch 9/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0042 - val_loss: 0.9539\n","Epoch 10/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0042 - val_loss: 0.9540\n","Epoch 11/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0041 - val_loss: 0.9541\n","Epoch 12/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0041 - val_loss: 0.9540\n","Epoch 13/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0041 - val_loss: 0.9541\n","Epoch 14/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0040 - val_loss: 0.9541\n","Epoch 15/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0040 - val_loss: 0.9541\n","Epoch 16/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0039 - val_loss: 0.9541\n","Epoch 17/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0038 - val_loss: 0.9541\n","Epoch 18/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0036 - val_loss: 0.9540\n","Epoch 19/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0033 - val_loss: 0.9538\n","Epoch 20/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0028 - val_loss: 0.9536\n","Epoch 21/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0023 - val_loss: 0.9530\n","Epoch 22/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0016 - val_loss: 0.9526\n","Epoch 23/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0008 - val_loss: 0.9515\n","Epoch 24/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9999 - val_loss: 0.9511\n","Epoch 25/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9989 - val_loss: 0.9492\n","Epoch 26/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9975 - val_loss: 0.9484\n","Epoch 27/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9959 - val_loss: 0.9477\n","Epoch 28/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9946 - val_loss: 0.9451\n","Epoch 29/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9923 - val_loss: 0.9438\n","Epoch 30/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9905 - val_loss: 0.9413\n","Epoch 31/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9881 - val_loss: 0.9395\n","Epoch 32/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9857 - val_loss: 0.9366\n","Epoch 33/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9833 - val_loss: 0.9351\n","Epoch 34/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9810 - val_loss: 0.9318\n","Epoch 35/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9801 - val_loss: 0.9294\n","Epoch 36/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9757 - val_loss: 0.9261\n","Epoch 37/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9725 - val_loss: 0.9237\n","Epoch 38/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9695 - val_loss: 0.9223\n","Epoch 39/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9675 - val_loss: 0.9176\n","Epoch 40/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9620 - val_loss: 0.9159\n","Epoch 41/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9602 - val_loss: 0.9139\n","Epoch 42/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9561 - val_loss: 0.9092\n","Epoch 43/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9532 - val_loss: 0.9059\n","Epoch 44/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9509 - val_loss: 0.9030\n","Epoch 45/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9468 - val_loss: 0.9002\n","Epoch 46/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9433 - val_loss: 0.8970\n","Epoch 47/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9422 - val_loss: 0.8945\n","Epoch 48/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9382 - val_loss: 0.8931\n","Epoch 49/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9356 - val_loss: 0.8913\n","Epoch 50/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9337 - val_loss: 0.8888\n","Epoch 51/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9306 - val_loss: 0.8860\n","Epoch 52/500\n","31/31 [==============================] - 1s 47ms/step - loss: 0.9289 - val_loss: 0.8843\n","Epoch 53/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9266 - val_loss: 0.8840\n","Epoch 54/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9262 - val_loss: 0.8812\n","Epoch 55/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9238 - val_loss: 0.8830\n","Epoch 56/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9226 - val_loss: 0.8809\n","Epoch 57/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9214 - val_loss: 0.8772\n","Epoch 58/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9201 - val_loss: 0.8761\n","Epoch 59/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9187 - val_loss: 0.8769\n","Epoch 60/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9188 - val_loss: 0.8743\n","Epoch 61/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9174 - val_loss: 0.8738\n","Epoch 62/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9169 - val_loss: 0.8729\n","Epoch 63/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9159 - val_loss: 0.8745\n","Epoch 64/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9151 - val_loss: 0.8724\n","Epoch 65/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9144 - val_loss: 0.8712\n","Epoch 66/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9140 - val_loss: 0.8708\n","Epoch 67/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9135 - val_loss: 0.8706\n","Epoch 68/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9130 - val_loss: 0.8702\n","Epoch 69/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9123 - val_loss: 0.8697\n","Epoch 70/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9125 - val_loss: 0.8698\n","Epoch 71/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9120 - val_loss: 0.8713\n","Epoch 72/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9118 - val_loss: 0.8682\n","Epoch 73/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9111 - val_loss: 0.8702\n","Epoch 74/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9106 - val_loss: 0.8686\n","Epoch 75/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9100 - val_loss: 0.8702\n","Epoch 76/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9098 - val_loss: 0.8679\n","Epoch 77/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9094 - val_loss: 0.8683\n","Epoch 78/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9091 - val_loss: 0.8691\n","Epoch 79/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9088 - val_loss: 0.8687\n","Epoch 80/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9084 - val_loss: 0.8671\n","Epoch 81/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9089 - val_loss: 0.8698\n","Epoch 82/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9080 - val_loss: 0.8676\n","Epoch 83/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9081 - val_loss: 0.8663\n","Epoch 84/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9077 - val_loss: 0.8693\n","Epoch 85/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9076 - val_loss: 0.8667\n","Epoch 86/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9071 - val_loss: 0.8678\n","Epoch 87/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9073 - val_loss: 0.8671\n","Epoch 88/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9069 - val_loss: 0.8667\n","Epoch 89/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9067 - val_loss: 0.8667\n","Epoch 90/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9061 - val_loss: 0.8666\n","Epoch 91/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9059 - val_loss: 0.8659\n","Epoch 92/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9056 - val_loss: 0.8656\n","Epoch 93/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9059 - val_loss: 0.8656\n","Epoch 94/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9054 - val_loss: 0.8665\n","Epoch 95/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9050 - val_loss: 0.8654\n","Epoch 96/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9049 - val_loss: 0.8677\n","Epoch 97/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9048 - val_loss: 0.8647\n","Epoch 98/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9047 - val_loss: 0.8650\n","Epoch 99/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9050 - val_loss: 0.8672\n","Epoch 100/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9051 - val_loss: 0.8656\n","Epoch 101/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9046 - val_loss: 0.8648\n","Epoch 102/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9043 - val_loss: 0.8651\n","Epoch 103/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9040 - val_loss: 0.8643\n","Epoch 104/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9042 - val_loss: 0.8645\n","Epoch 105/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9044 - val_loss: 0.8650\n","Epoch 106/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9040 - val_loss: 0.8643\n","Epoch 107/500\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9038 - val_loss: 0.8654\n","Epoch 108/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9043 - val_loss: 0.8677\n","Epoch 109/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9037 - val_loss: 0.8655\n","Epoch 110/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9034 - val_loss: 0.8641\n","Epoch 111/500\n","31/31 [==============================] - 2s 54ms/step - loss: 0.9035 - val_loss: 0.8709\n","34/34 [==============================] - 0s 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f1ab337d4d94bd593921b689ff34bb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>██████████▇▇▆▆▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>110</td></tr><tr><td>epoch/learning_rate</td><td>0.0005</td></tr><tr><td>epoch/loss</td><td>0.90349</td></tr><tr><td>epoch/val_loss</td><td>0.87091</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">early_stopping_patience_50</strong> at: <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/wvfkrggd' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/wvfkrggd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240214_121546-wvfkrggd/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240214_121729-o7m4k7dm</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/o7m4k7dm' target=\"_blank\">early_stopping_patience_50</a></strong> to <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/o7m4k7dm' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/o7m4k7dm</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 17162)]           0         \n","                                                                 \n"," dense_16 (Dense)            (None, 8000)              137304000 \n","                                                                 \n"," dense_17 (Dense)            (None, 1000)              8001000   \n","                                                                 \n"," dense_18 (Dense)            (None, 200)               200200    \n","                                                                 \n"," reshape_4 (Reshape)         (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_4 (SeqS  (None, 200, 1)            129       \n"," elfAttention)                                                   \n","                                                                 \n"," flatten_4 (Flatten)         (None, 200)               0         \n","                                                                 \n"," dense_19 (Dense)            (None, 10)                2010      \n","                                                                 \n"," dense_20 (Dense)            (None, 200)               2200      \n","                                                                 \n"," reshape_5 (Reshape)         (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_5 (SeqS  (None, 200, 1)            129       \n"," elfAttention)                                                   \n","                                                                 \n"," flatten_5 (Flatten)         (None, 200)               0         \n","                                                                 \n"," dense_21 (Dense)            (None, 1000)              201000    \n","                                                                 \n"," dense_22 (Dense)            (None, 8000)              8008000   \n","                                                                 \n"," dense_23 (Dense)            (None, 17162)             137313162 \n","                                                                 \n","=================================================================\n","Total params: 291031830 (1.08 GB)\n","Trainable params: 291031830 (1.08 GB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/500\n"," 5/31 [===>..........................] - ETA: 0s - loss: 1.5006"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0111s vs `on_train_batch_end` time: 0.0117s). Check your callbacks.\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 6s 79ms/step - loss: 1.1141 - val_loss: 1.0201\n","Epoch 2/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9974 - val_loss: 1.0191\n","Epoch 3/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9971 - val_loss: 1.0191\n","Epoch 4/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9970 - val_loss: 1.0192\n","Epoch 5/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9970 - val_loss: 1.0193\n","Epoch 6/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9969 - val_loss: 1.0194\n","Epoch 7/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9969 - val_loss: 1.0194\n","Epoch 8/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9969 - val_loss: 1.0195\n","Epoch 9/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9968 - val_loss: 1.0195\n","Epoch 10/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9968 - val_loss: 1.0196\n","Epoch 11/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9967 - val_loss: 1.0196\n","Epoch 12/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9967 - val_loss: 1.0196\n","Epoch 13/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9966 - val_loss: 1.0197\n","Epoch 14/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9965 - val_loss: 1.0196\n","Epoch 15/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9964 - val_loss: 1.0196\n","Epoch 16/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9962 - val_loss: 1.0195\n","Epoch 17/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9960 - val_loss: 1.0194\n","Epoch 18/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9956 - val_loss: 1.0193\n","Epoch 19/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9950 - val_loss: 1.0189\n","Epoch 20/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9946 - val_loss: 1.0180\n","Epoch 21/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9937 - val_loss: 1.0174\n","Epoch 22/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9929 - val_loss: 1.0167\n","Epoch 23/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9922 - val_loss: 1.0160\n","Epoch 24/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9914 - val_loss: 1.0144\n","Epoch 25/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9903 - val_loss: 1.0137\n","Epoch 26/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9888 - val_loss: 1.0130\n","Epoch 27/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9874 - val_loss: 1.0104\n","Epoch 28/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9856 - val_loss: 1.0083\n","Epoch 29/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9839 - val_loss: 1.0068\n","Epoch 30/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9834 - val_loss: 1.0044\n","Epoch 31/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9796 - val_loss: 1.0025\n","Epoch 32/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9776 - val_loss: 0.9998\n","Epoch 33/500\n","31/31 [==============================] - 1s 47ms/step - loss: 0.9752 - val_loss: 0.9969\n","Epoch 34/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9726 - val_loss: 0.9941\n","Epoch 35/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9700 - val_loss: 0.9906\n","Epoch 36/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9670 - val_loss: 0.9872\n","Epoch 37/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9647 - val_loss: 0.9869\n","Epoch 38/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9643 - val_loss: 0.9820\n","Epoch 39/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9586 - val_loss: 0.9783\n","Epoch 40/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9556 - val_loss: 0.9753\n","Epoch 41/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9536 - val_loss: 0.9765\n","Epoch 42/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9516 - val_loss: 0.9707\n","Epoch 43/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9478 - val_loss: 0.9659\n","Epoch 44/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9447 - val_loss: 0.9649\n","Epoch 45/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9420 - val_loss: 0.9593\n","Epoch 46/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9395 - val_loss: 0.9616\n","Epoch 47/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9380 - val_loss: 0.9559\n","Epoch 48/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9368 - val_loss: 0.9520\n","Epoch 49/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9323 - val_loss: 0.9491\n","Epoch 50/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9302 - val_loss: 0.9459\n","Epoch 51/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9270 - val_loss: 0.9424\n","Epoch 52/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9246 - val_loss: 0.9403\n","Epoch 53/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9227 - val_loss: 0.9380\n","Epoch 54/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9213 - val_loss: 0.9351\n","Epoch 55/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9191 - val_loss: 0.9336\n","Epoch 56/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9180 - val_loss: 0.9323\n","Epoch 57/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9163 - val_loss: 0.9300\n","Epoch 58/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9158 - val_loss: 0.9308\n","Epoch 59/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9147 - val_loss: 0.9276\n","Epoch 60/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9133 - val_loss: 0.9256\n","Epoch 61/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9125 - val_loss: 0.9279\n","Epoch 62/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9118 - val_loss: 0.9236\n","Epoch 63/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9111 - val_loss: 0.9235\n","Epoch 64/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9099 - val_loss: 0.9214\n","Epoch 65/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9092 - val_loss: 0.9207\n","Epoch 66/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9086 - val_loss: 0.9208\n","Epoch 67/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9085 - val_loss: 0.9194\n","Epoch 68/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9080 - val_loss: 0.9183\n","Epoch 69/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9073 - val_loss: 0.9175\n","Epoch 70/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9067 - val_loss: 0.9172\n","Epoch 71/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9062 - val_loss: 0.9172\n","Epoch 72/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9059 - val_loss: 0.9159\n","Epoch 73/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9056 - val_loss: 0.9159\n","Epoch 74/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9052 - val_loss: 0.9150\n","Epoch 75/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9049 - val_loss: 0.9146\n","Epoch 76/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9042 - val_loss: 0.9141\n","Epoch 77/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9039 - val_loss: 0.9136\n","Epoch 78/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9039 - val_loss: 0.9141\n","Epoch 79/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9041 - val_loss: 0.9143\n","Epoch 80/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9036 - val_loss: 0.9129\n","Epoch 81/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9030 - val_loss: 0.9124\n","Epoch 82/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9028 - val_loss: 0.9116\n","Epoch 83/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9025 - val_loss: 0.9109\n","Epoch 84/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9022 - val_loss: 0.9108\n","Epoch 85/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9021 - val_loss: 0.9111\n","Epoch 86/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9019 - val_loss: 0.9106\n","Epoch 87/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9017 - val_loss: 0.9100\n","Epoch 88/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9015 - val_loss: 0.9103\n","Epoch 89/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9015 - val_loss: 0.9102\n","Epoch 90/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9014 - val_loss: 0.9099\n","Epoch 91/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9011 - val_loss: 0.9094\n","Epoch 92/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9010 - val_loss: 0.9099\n","Epoch 93/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9008 - val_loss: 0.9085\n","Epoch 94/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9008 - val_loss: 0.9080\n","Epoch 95/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9005 - val_loss: 0.9083\n","Epoch 96/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9003 - val_loss: 0.9078\n","Epoch 97/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9005 - val_loss: 0.9071\n","Epoch 98/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9007 - val_loss: 0.9074\n","Epoch 99/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9002 - val_loss: 0.9079\n","Epoch 100/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9000 - val_loss: 0.9081\n","Epoch 101/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8998 - val_loss: 0.9072\n","Epoch 102/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8998 - val_loss: 0.9070\n","Epoch 103/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8997 - val_loss: 0.9072\n","Epoch 104/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9002 - val_loss: 0.9070\n","Epoch 105/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8997 - val_loss: 0.9065\n","Epoch 106/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8993 - val_loss: 0.9073\n","Epoch 107/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8998 - val_loss: 0.9065\n","Epoch 108/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8993 - val_loss: 0.9062\n","Epoch 109/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8991 - val_loss: 0.9056\n","Epoch 110/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8994 - val_loss: 0.9054\n","Epoch 111/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8988 - val_loss: 0.9070\n","Epoch 112/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8988 - val_loss: 0.9058\n","Epoch 113/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8987 - val_loss: 0.9057\n","Epoch 114/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8987 - val_loss: 0.9044\n","Epoch 115/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8985 - val_loss: 0.9057\n","Epoch 116/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8981 - val_loss: 0.9043\n","Epoch 117/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8980 - val_loss: 0.9041\n","Epoch 118/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8981 - val_loss: 0.9049\n","Epoch 119/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8987 - val_loss: 0.9048\n","Epoch 120/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8982 - val_loss: 0.9037\n","Epoch 121/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8980 - val_loss: 0.9040\n","Epoch 122/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8978 - val_loss: 0.9052\n","Epoch 123/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8986 - val_loss: 0.9039\n","Epoch 124/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8979 - val_loss: 0.9041\n","Epoch 125/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8977 - val_loss: 0.9042\n","Epoch 126/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8977 - val_loss: 0.9040\n","Epoch 127/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8976 - val_loss: 0.9039\n","Epoch 128/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8974 - val_loss: 0.9030\n","Epoch 129/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8975 - val_loss: 0.9027\n","Epoch 130/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8972 - val_loss: 0.9033\n","Epoch 131/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8976 - val_loss: 0.9027\n","Epoch 132/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8977 - val_loss: 0.9028\n","Epoch 133/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8974 - val_loss: 0.9027\n","Epoch 134/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8970 - val_loss: 0.9024\n","Epoch 135/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8967 - val_loss: 0.9028\n","Epoch 136/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8973 - val_loss: 0.9030\n","Epoch 137/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8973 - val_loss: 0.9023\n","Epoch 138/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8969 - val_loss: 0.9023\n","Epoch 139/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8970 - val_loss: 0.9024\n","Epoch 140/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8968 - val_loss: 0.9031\n","Epoch 141/500\n","31/31 [==============================] - 2s 54ms/step - loss: 0.8968 - val_loss: 0.9018\n","34/34 [==============================] - 0s 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69776819526d445dac35553c3d095d51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>███████▇▇▇▆▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>████████▇▇▆▅▅▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>140</td></tr><tr><td>epoch/learning_rate</td><td>0.0005</td></tr><tr><td>epoch/loss</td><td>0.89677</td></tr><tr><td>epoch/val_loss</td><td>0.90184</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">early_stopping_patience_50</strong> at: <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/o7m4k7dm' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/o7m4k7dm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240214_121729-o7m4k7dm/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240214_121939-qkg7iiyx</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/qkg7iiyx' target=\"_blank\">early_stopping_patience_50</a></strong> to <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/qkg7iiyx' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/qkg7iiyx</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model: \"model_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 17162)]           0         \n","                                                                 \n"," dense_24 (Dense)            (None, 8000)              137304000 \n","                                                                 \n"," dense_25 (Dense)            (None, 1000)              8001000   \n","                                                                 \n"," dense_26 (Dense)            (None, 200)               200200    \n","                                                                 \n"," reshape_6 (Reshape)         (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_6 (SeqS  (None, 200, 1)            129       \n"," elfAttention)                                                   \n","                                                                 \n"," flatten_6 (Flatten)         (None, 200)               0         \n","                                                                 \n"," dense_27 (Dense)            (None, 10)                2010      \n","                                                                 \n"," dense_28 (Dense)            (None, 200)               2200      \n","                                                                 \n"," reshape_7 (Reshape)         (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_7 (SeqS  (None, 200, 1)            129       \n"," elfAttention)                                                   \n","                                                                 \n"," flatten_7 (Flatten)         (None, 200)               0         \n","                                                                 \n"," dense_29 (Dense)            (None, 1000)              201000    \n","                                                                 \n"," dense_30 (Dense)            (None, 8000)              8008000   \n","                                                                 \n"," dense_31 (Dense)            (None, 17162)             137313162 \n","                                                                 \n","=================================================================\n","Total params: 291031830 (1.08 GB)\n","Trainable params: 291031830 (1.08 GB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/500\n"," 5/31 [===>..........................] - ETA: 0s - loss: 1.5731"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0110s vs `on_train_batch_end` time: 0.0118s). Check your callbacks.\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 6s 80ms/step - loss: 1.1212 - val_loss: 0.9663\n","Epoch 2/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0034 - val_loss: 0.9651\n","Epoch 3/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0031 - val_loss: 0.9651\n","Epoch 4/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0031 - val_loss: 0.9651\n","Epoch 5/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0030 - val_loss: 0.9651\n","Epoch 6/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0030 - val_loss: 0.9652\n","Epoch 7/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0030 - val_loss: 0.9653\n","Epoch 8/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0030 - val_loss: 0.9653\n","Epoch 9/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0030 - val_loss: 0.9653\n","Epoch 10/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0029 - val_loss: 0.9654\n","Epoch 11/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0029 - val_loss: 0.9655\n","Epoch 12/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0029 - val_loss: 0.9655\n","Epoch 13/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0029 - val_loss: 0.9656\n","Epoch 14/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0029 - val_loss: 0.9656\n","Epoch 15/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0029 - val_loss: 0.9656\n","Epoch 16/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0029 - val_loss: 0.9657\n","Epoch 17/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0028 - val_loss: 0.9656\n","Epoch 18/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0028 - val_loss: 0.9657\n","Epoch 19/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0028 - val_loss: 0.9657\n","Epoch 20/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0027 - val_loss: 0.9658\n","Epoch 21/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0026 - val_loss: 0.9659\n","Epoch 22/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0025 - val_loss: 0.9658\n","Epoch 23/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0023 - val_loss: 0.9657\n","Epoch 24/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0021 - val_loss: 0.9655\n","Epoch 25/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0016 - val_loss: 0.9652\n","Epoch 26/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0012 - val_loss: 0.9649\n","Epoch 27/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0004 - val_loss: 0.9641\n","Epoch 28/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9995 - val_loss: 0.9637\n","Epoch 29/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9987 - val_loss: 0.9619\n","Epoch 30/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9977 - val_loss: 0.9626\n","Epoch 31/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9965 - val_loss: 0.9597\n","Epoch 32/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9964 - val_loss: 0.9586\n","Epoch 33/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9949 - val_loss: 0.9575\n","Epoch 34/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9921 - val_loss: 0.9547\n","Epoch 35/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9901 - val_loss: 0.9527\n","Epoch 36/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9887 - val_loss: 0.9507\n","Epoch 37/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9856 - val_loss: 0.9483\n","Epoch 38/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9835 - val_loss: 0.9453\n","Epoch 39/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9815 - val_loss: 0.9419\n","Epoch 40/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9791 - val_loss: 0.9389\n","Epoch 41/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9750 - val_loss: 0.9360\n","Epoch 42/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9726 - val_loss: 0.9324\n","Epoch 43/500\n","31/31 [==============================] - 1s 47ms/step - loss: 0.9697 - val_loss: 0.9287\n","Epoch 44/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9667 - val_loss: 0.9280\n","Epoch 45/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9651 - val_loss: 0.9226\n","Epoch 46/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9609 - val_loss: 0.9188\n","Epoch 47/500\n","31/31 [==============================] - 1s 47ms/step - loss: 0.9592 - val_loss: 0.9155\n","Epoch 48/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9544 - val_loss: 0.9113\n","Epoch 49/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9516 - val_loss: 0.9102\n","Epoch 50/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9491 - val_loss: 0.9050\n","Epoch 51/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9460 - val_loss: 0.9023\n","Epoch 52/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9433 - val_loss: 0.8995\n","Epoch 53/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9406 - val_loss: 0.8957\n","Epoch 54/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9376 - val_loss: 0.8935\n","Epoch 55/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9354 - val_loss: 0.8892\n","Epoch 56/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9325 - val_loss: 0.8866\n","Epoch 57/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9301 - val_loss: 0.8846\n","Epoch 58/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9284 - val_loss: 0.8817\n","Epoch 59/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9264 - val_loss: 0.8794\n","Epoch 60/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9251 - val_loss: 0.8767\n","Epoch 61/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9228 - val_loss: 0.8750\n","Epoch 62/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9219 - val_loss: 0.8761\n","Epoch 63/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9207 - val_loss: 0.8749\n","Epoch 64/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9203 - val_loss: 0.8711\n","Epoch 65/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9186 - val_loss: 0.8696\n","Epoch 66/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9175 - val_loss: 0.8685\n","Epoch 67/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9166 - val_loss: 0.8687\n","Epoch 68/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9160 - val_loss: 0.8672\n","Epoch 69/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9149 - val_loss: 0.8657\n","Epoch 70/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9147 - val_loss: 0.8654\n","Epoch 71/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9143 - val_loss: 0.8663\n","Epoch 72/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9135 - val_loss: 0.8633\n","Epoch 73/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9133 - val_loss: 0.8645\n","Epoch 74/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9141 - val_loss: 0.8624\n","Epoch 75/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9119 - val_loss: 0.8617\n","Epoch 76/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9113 - val_loss: 0.8612\n","Epoch 77/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9114 - val_loss: 0.8619\n","Epoch 78/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9108 - val_loss: 0.8610\n","Epoch 79/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9110 - val_loss: 0.8606\n","Epoch 80/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9101 - val_loss: 0.8600\n","Epoch 81/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9095 - val_loss: 0.8601\n","Epoch 82/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9095 - val_loss: 0.8584\n","Epoch 83/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9094 - val_loss: 0.8589\n","Epoch 84/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9086 - val_loss: 0.8581\n","Epoch 85/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9085 - val_loss: 0.8579\n","Epoch 86/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9080 - val_loss: 0.8572\n","Epoch 87/500\n","31/31 [==============================] - 1s 26ms/step - loss: 0.9077 - val_loss: 0.8573\n","Epoch 88/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9075 - val_loss: 0.8570\n","Epoch 89/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9072 - val_loss: 0.8563\n","Epoch 90/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9072 - val_loss: 0.8560\n","Epoch 91/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9070 - val_loss: 0.8566\n","Epoch 92/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9066 - val_loss: 0.8569\n","Epoch 93/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9065 - val_loss: 0.8556\n","Epoch 94/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9065 - val_loss: 0.8557\n","Epoch 95/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9061 - val_loss: 0.8553\n","Epoch 96/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9063 - val_loss: 0.8557\n","Epoch 97/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9065 - val_loss: 0.8562\n","Epoch 98/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9062 - val_loss: 0.8557\n","Epoch 99/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9057 - val_loss: 0.8555\n","Epoch 100/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9058 - val_loss: 0.8545\n","Epoch 101/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9054 - val_loss: 0.8540\n","Epoch 102/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9050 - val_loss: 0.8543\n","Epoch 103/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9049 - val_loss: 0.8545\n","Epoch 104/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9050 - val_loss: 0.8547\n","Epoch 105/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9052 - val_loss: 0.8561\n","Epoch 106/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9049 - val_loss: 0.8533\n","Epoch 107/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9044 - val_loss: 0.8535\n","Epoch 108/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9043 - val_loss: 0.8539\n","Epoch 109/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9043 - val_loss: 0.8536\n","Epoch 110/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9044 - val_loss: 0.8547\n","Epoch 111/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9044 - val_loss: 0.8539\n","Epoch 112/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9040 - val_loss: 0.8532\n","Epoch 113/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9040 - val_loss: 0.8547\n","Epoch 114/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9042 - val_loss: 0.8535\n","Epoch 115/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9038 - val_loss: 0.8535\n","Epoch 116/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9033 - val_loss: 0.8530\n","Epoch 117/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9034 - val_loss: 0.8539\n","Epoch 118/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9034 - val_loss: 0.8529\n","Epoch 119/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9033 - val_loss: 0.8526\n","Epoch 120/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9032 - val_loss: 0.8529\n","Epoch 121/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9033 - val_loss: 0.8532\n","Epoch 122/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9030 - val_loss: 0.8533\n","Epoch 123/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9029 - val_loss: 0.8524\n","Epoch 124/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9032 - val_loss: 0.8538\n","Epoch 125/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9028 - val_loss: 0.8529\n","Epoch 126/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9025 - val_loss: 0.8526\n","Epoch 127/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9024 - val_loss: 0.8525\n","Epoch 128/500\n","31/31 [==============================] - 2s 54ms/step - loss: 0.9024 - val_loss: 0.8519\n","34/34 [==============================] - 0s 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ddecf9b347647f99d4d52524d7dd9c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>██████████▇▇▆▅▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>██████████▇▇▆▆▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>127</td></tr><tr><td>epoch/learning_rate</td><td>0.0005</td></tr><tr><td>epoch/loss</td><td>0.90243</td></tr><tr><td>epoch/val_loss</td><td>0.85189</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">early_stopping_patience_50</strong> at: <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/qkg7iiyx' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/qkg7iiyx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240214_121939-qkg7iiyx/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240214_122135-vpfjxsr1</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/vpfjxsr1' target=\"_blank\">early_stopping_patience_50</a></strong> to <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/vpfjxsr1' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/vpfjxsr1</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model: \"model_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 17162)]           0         \n","                                                                 \n"," dense_32 (Dense)            (None, 8000)              137304000 \n","                                                                 \n"," dense_33 (Dense)            (None, 1000)              8001000   \n","                                                                 \n"," dense_34 (Dense)            (None, 200)               200200    \n","                                                                 \n"," reshape_8 (Reshape)         (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_8 (SeqS  (None, 200, 1)            129       \n"," elfAttention)                                                   \n","                                                                 \n"," flatten_8 (Flatten)         (None, 200)               0         \n","                                                                 \n"," dense_35 (Dense)            (None, 10)                2010      \n","                                                                 \n"," dense_36 (Dense)            (None, 200)               2200      \n","                                                                 \n"," reshape_9 (Reshape)         (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_9 (SeqS  (None, 200, 1)            129       \n"," elfAttention)                                                   \n","                                                                 \n"," flatten_9 (Flatten)         (None, 200)               0         \n","                                                                 \n"," dense_37 (Dense)            (None, 1000)              201000    \n","                                                                 \n"," dense_38 (Dense)            (None, 8000)              8008000   \n","                                                                 \n"," dense_39 (Dense)            (None, 17162)             137313162 \n","                                                                 \n","=================================================================\n","Total params: 291031830 (1.08 GB)\n","Trainable params: 291031830 (1.08 GB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/500\n"," 6/31 [====>.........................] - ETA: 0s - loss: 1.5035"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0108s vs `on_train_batch_end` time: 0.0138s). Check your callbacks.\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 6s 81ms/step - loss: 1.1162 - val_loss: 1.0248\n","Epoch 2/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9970 - val_loss: 1.0233\n","Epoch 3/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9967 - val_loss: 1.0232\n","Epoch 4/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9966 - val_loss: 1.0232\n","Epoch 5/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9966 - val_loss: 1.0232\n","Epoch 6/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9965 - val_loss: 1.0232\n","Epoch 7/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9965 - val_loss: 1.0232\n","Epoch 8/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9964 - val_loss: 1.0232\n","Epoch 9/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9964 - val_loss: 1.0233\n","Epoch 10/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9963 - val_loss: 1.0234\n","Epoch 11/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9963 - val_loss: 1.0234\n","Epoch 12/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9962 - val_loss: 1.0234\n","Epoch 13/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9960 - val_loss: 1.0235\n","Epoch 14/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9958 - val_loss: 1.0235\n","Epoch 15/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9955 - val_loss: 1.0236\n","Epoch 16/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9950 - val_loss: 1.0237\n","Epoch 17/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9941 - val_loss: 1.0236\n","Epoch 18/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9929 - val_loss: 1.0235\n","Epoch 19/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9915 - val_loss: 1.0222\n","Epoch 20/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9897 - val_loss: 1.0218\n","Epoch 21/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9875 - val_loss: 1.0201\n","Epoch 22/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9850 - val_loss: 1.0198\n","Epoch 23/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9827 - val_loss: 1.0145\n","Epoch 24/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9788 - val_loss: 1.0127\n","Epoch 25/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9755 - val_loss: 1.0102\n","Epoch 26/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9711 - val_loss: 1.0061\n","Epoch 27/500\n","31/31 [==============================] - 1s 47ms/step - loss: 0.9663 - val_loss: 1.0020\n","Epoch 28/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9622 - val_loss: 1.0014\n","Epoch 29/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9575 - val_loss: 1.0006\n","Epoch 30/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9535 - val_loss: 0.9922\n","Epoch 31/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9502 - val_loss: 0.9926\n","Epoch 32/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9453 - val_loss: 0.9858\n","Epoch 33/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9425 - val_loss: 0.9812\n","Epoch 34/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9385 - val_loss: 0.9803\n","Epoch 35/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9360 - val_loss: 0.9770\n","Epoch 36/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9322 - val_loss: 0.9742\n","Epoch 37/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9301 - val_loss: 0.9763\n","Epoch 38/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9279 - val_loss: 0.9703\n","Epoch 39/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9256 - val_loss: 0.9686\n","Epoch 40/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9234 - val_loss: 0.9673\n","Epoch 41/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9215 - val_loss: 0.9674\n","Epoch 42/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9204 - val_loss: 0.9636\n","Epoch 43/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9189 - val_loss: 0.9642\n","Epoch 44/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9180 - val_loss: 0.9609\n","Epoch 45/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9165 - val_loss: 0.9593\n","Epoch 46/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9150 - val_loss: 0.9585\n","Epoch 47/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9141 - val_loss: 0.9575\n","Epoch 48/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9133 - val_loss: 0.9566\n","Epoch 49/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9125 - val_loss: 0.9557\n","Epoch 50/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9115 - val_loss: 0.9547\n","Epoch 51/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9114 - val_loss: 0.9544\n","Epoch 52/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9105 - val_loss: 0.9542\n","Epoch 53/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9099 - val_loss: 0.9530\n","Epoch 54/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9097 - val_loss: 0.9524\n","Epoch 55/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9087 - val_loss: 0.9513\n","Epoch 56/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9082 - val_loss: 0.9510\n","Epoch 57/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9079 - val_loss: 0.9501\n","Epoch 58/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9069 - val_loss: 0.9491\n","Epoch 59/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9063 - val_loss: 0.9484\n","Epoch 60/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9061 - val_loss: 0.9483\n","Epoch 61/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9057 - val_loss: 0.9477\n","Epoch 62/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9054 - val_loss: 0.9473\n","Epoch 63/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9050 - val_loss: 0.9470\n","Epoch 64/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9046 - val_loss: 0.9462\n","Epoch 65/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9041 - val_loss: 0.9460\n","Epoch 66/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9037 - val_loss: 0.9453\n","Epoch 67/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9035 - val_loss: 0.9448\n","Epoch 68/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9033 - val_loss: 0.9447\n","Epoch 69/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9034 - val_loss: 0.9440\n","Epoch 70/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9030 - val_loss: 0.9429\n","Epoch 71/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9022 - val_loss: 0.9430\n","Epoch 72/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9018 - val_loss: 0.9432\n","Epoch 73/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9021 - val_loss: 0.9416\n","Epoch 74/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9015 - val_loss: 0.9420\n","Epoch 75/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9012 - val_loss: 0.9414\n","Epoch 76/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9010 - val_loss: 0.9414\n","Epoch 77/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9008 - val_loss: 0.9405\n","Epoch 78/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9004 - val_loss: 0.9419\n","Epoch 79/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9004 - val_loss: 0.9405\n","Epoch 80/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9001 - val_loss: 0.9402\n","Epoch 81/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8998 - val_loss: 0.9393\n","Epoch 82/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8997 - val_loss: 0.9387\n","Epoch 83/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8994 - val_loss: 0.9392\n","Epoch 84/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8992 - val_loss: 0.9383\n","Epoch 85/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8992 - val_loss: 0.9383\n","Epoch 86/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8992 - val_loss: 0.9377\n","Epoch 87/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8992 - val_loss: 0.9374\n","Epoch 88/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8988 - val_loss: 0.9372\n","Epoch 89/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8985 - val_loss: 0.9368\n","Epoch 90/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8981 - val_loss: 0.9368\n","Epoch 91/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8981 - val_loss: 0.9361\n","Epoch 92/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8979 - val_loss: 0.9361\n","Epoch 93/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8982 - val_loss: 0.9361\n","Epoch 94/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8978 - val_loss: 0.9357\n","Epoch 95/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8974 - val_loss: 0.9365\n","Epoch 96/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8977 - val_loss: 0.9359\n","Epoch 97/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8973 - val_loss: 0.9401\n","Epoch 98/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8985 - val_loss: 0.9348\n","Epoch 99/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8971 - val_loss: 0.9365\n","Epoch 100/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8971 - val_loss: 0.9352\n","Epoch 101/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8975 - val_loss: 0.9342\n","Epoch 102/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8973 - val_loss: 0.9345\n","Epoch 103/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8969 - val_loss: 0.9343\n","Epoch 104/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8965 - val_loss: 0.9341\n","Epoch 105/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8964 - val_loss: 0.9333\n","Epoch 106/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8965 - val_loss: 0.9333\n","Epoch 107/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8963 - val_loss: 0.9330\n","Epoch 108/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.8961 - val_loss: 0.9328\n","Epoch 109/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8961 - val_loss: 0.9323\n","Epoch 110/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8960 - val_loss: 0.9334\n","Epoch 111/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8964 - val_loss: 0.9324\n","Epoch 112/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8959 - val_loss: 0.9325\n","Epoch 113/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8956 - val_loss: 0.9321\n","Epoch 114/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8954 - val_loss: 0.9317\n","Epoch 115/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8955 - val_loss: 0.9318\n","Epoch 116/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8956 - val_loss: 0.9320\n","Epoch 117/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8955 - val_loss: 0.9328\n","Epoch 118/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8956 - val_loss: 0.9315\n","Epoch 119/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8952 - val_loss: 0.9311\n","Epoch 120/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8953 - val_loss: 0.9310\n","Epoch 121/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8951 - val_loss: 0.9312\n","Epoch 122/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8949 - val_loss: 0.9310\n","Epoch 123/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8949 - val_loss: 0.9303\n","Epoch 124/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8947 - val_loss: 0.9305\n","Epoch 125/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8948 - val_loss: 0.9302\n","Epoch 126/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8947 - val_loss: 0.9301\n","Epoch 127/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8949 - val_loss: 0.9295\n","Epoch 128/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8944 - val_loss: 0.9295\n","Epoch 129/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8945 - val_loss: 0.9296\n","Epoch 130/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8945 - val_loss: 0.9302\n","Epoch 131/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8943 - val_loss: 0.9293\n","Epoch 132/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8944 - val_loss: 0.9308\n","Epoch 133/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8946 - val_loss: 0.9298\n","Epoch 134/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8943 - val_loss: 0.9298\n","Epoch 135/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8941 - val_loss: 0.9291\n","Epoch 136/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8944 - val_loss: 0.9289\n","Epoch 137/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8941 - val_loss: 0.9290\n","Epoch 138/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8940 - val_loss: 0.9288\n","Epoch 139/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8948 - val_loss: 0.9287\n","Epoch 140/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8947 - val_loss: 0.9291\n","Epoch 141/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8941 - val_loss: 0.9287\n","Epoch 142/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8945 - val_loss: 0.9293\n","Epoch 143/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8940 - val_loss: 0.9295\n","Epoch 144/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8937 - val_loss: 0.9282\n","Epoch 145/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8938 - val_loss: 0.9282\n","Epoch 146/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8939 - val_loss: 0.9307\n","Epoch 147/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8943 - val_loss: 0.9284\n","Epoch 148/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8940 - val_loss: 0.9288\n","Epoch 149/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8943 - val_loss: 0.9284\n","Epoch 150/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8940 - val_loss: 0.9278\n","Epoch 151/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8937 - val_loss: 0.9285\n","Epoch 152/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8934 - val_loss: 0.9279\n","Epoch 153/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8938 - val_loss: 0.9277\n","Epoch 154/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8937 - val_loss: 0.9278\n","Epoch 155/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8932 - val_loss: 0.9278\n","Epoch 156/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8935 - val_loss: 0.9305\n","Epoch 157/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8949 - val_loss: 0.9308\n","Epoch 158/500\n","31/31 [==============================] - 2s 54ms/step - loss: 0.8959 - val_loss: 0.9313\n","34/34 [==============================] - 0s 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f7d78c6fba449838a29429bf5c865d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█████▇▆▅▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>██████▇▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>157</td></tr><tr><td>epoch/learning_rate</td><td>0.0005</td></tr><tr><td>epoch/loss</td><td>0.8959</td></tr><tr><td>epoch/val_loss</td><td>0.93129</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">early_stopping_patience_50</strong> at: <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/vpfjxsr1' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/vpfjxsr1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240214_122135-vpfjxsr1/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240214_122354-k21sp125</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/k21sp125' target=\"_blank\">early_stopping_patience_50</a></strong> to <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/k21sp125' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/k21sp125</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model: \"model_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 17162)]           0         \n","                                                                 \n"," dense_40 (Dense)            (None, 8000)              137304000 \n","                                                                 \n"," dense_41 (Dense)            (None, 1000)              8001000   \n","                                                                 \n"," dense_42 (Dense)            (None, 200)               200200    \n","                                                                 \n"," reshape_10 (Reshape)        (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_10 (Seq  (None, 200, 1)            129       \n"," SelfAttention)                                                  \n","                                                                 \n"," flatten_10 (Flatten)        (None, 200)               0         \n","                                                                 \n"," dense_43 (Dense)            (None, 10)                2010      \n","                                                                 \n"," dense_44 (Dense)            (None, 200)               2200      \n","                                                                 \n"," reshape_11 (Reshape)        (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_11 (Seq  (None, 200, 1)            129       \n"," SelfAttention)                                                  \n","                                                                 \n"," flatten_11 (Flatten)        (None, 200)               0         \n","                                                                 \n"," dense_45 (Dense)            (None, 1000)              201000    \n","                                                                 \n"," dense_46 (Dense)            (None, 8000)              8008000   \n","                                                                 \n"," dense_47 (Dense)            (None, 17162)             137313162 \n","                                                                 \n","=================================================================\n","Total params: 291031830 (1.08 GB)\n","Trainable params: 291031830 (1.08 GB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/500\n"," 5/31 [===>..........................] - ETA: 0s - loss: 1.4479"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0112s vs `on_train_batch_end` time: 0.0118s). Check your callbacks.\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 7s 89ms/step - loss: 1.1157 - val_loss: 1.0281\n","Epoch 2/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9965 - val_loss: 1.0273\n","Epoch 3/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9962 - val_loss: 1.0273\n","Epoch 4/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9961 - val_loss: 1.0273\n","Epoch 5/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9961 - val_loss: 1.0274\n","Epoch 6/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9961 - val_loss: 1.0274\n","Epoch 7/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9960 - val_loss: 1.0275\n","Epoch 8/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9960 - val_loss: 1.0275\n","Epoch 9/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9960 - val_loss: 1.0276\n","Epoch 10/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9960 - val_loss: 1.0277\n","Epoch 11/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9960 - val_loss: 1.0277\n","Epoch 12/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9959 - val_loss: 1.0277\n","Epoch 13/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9959 - val_loss: 1.0277\n","Epoch 14/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9959 - val_loss: 1.0277\n","Epoch 15/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9959 - val_loss: 1.0277\n","Epoch 16/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9958 - val_loss: 1.0277\n","Epoch 17/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9958 - val_loss: 1.0277\n","Epoch 18/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9957 - val_loss: 1.0277\n","Epoch 19/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9956 - val_loss: 1.0276\n","Epoch 20/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9955 - val_loss: 1.0275\n","Epoch 21/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9953 - val_loss: 1.0273\n","Epoch 22/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9949 - val_loss: 1.0269\n","Epoch 23/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9946 - val_loss: 1.0262\n","Epoch 24/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9940 - val_loss: 1.0255\n","Epoch 25/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9933 - val_loss: 1.0247\n","Epoch 26/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9924 - val_loss: 1.0236\n","Epoch 27/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9916 - val_loss: 1.0228\n","Epoch 28/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9910 - val_loss: 1.0211\n","Epoch 29/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9895 - val_loss: 1.0201\n","Epoch 30/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9883 - val_loss: 1.0185\n","Epoch 31/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9863 - val_loss: 1.0167\n","Epoch 32/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9855 - val_loss: 1.0149\n","Epoch 33/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9825 - val_loss: 1.0136\n","Epoch 34/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9809 - val_loss: 1.0098\n","Epoch 35/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9788 - val_loss: 1.0086\n","Epoch 36/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9765 - val_loss: 1.0059\n","Epoch 37/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9741 - val_loss: 1.0025\n","Epoch 38/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9712 - val_loss: 0.9988\n","Epoch 39/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9682 - val_loss: 0.9979\n","Epoch 40/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9658 - val_loss: 0.9927\n","Epoch 41/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9627 - val_loss: 0.9890\n","Epoch 42/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9596 - val_loss: 0.9869\n","Epoch 43/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9562 - val_loss: 0.9825\n","Epoch 44/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9530 - val_loss: 0.9805\n","Epoch 45/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9505 - val_loss: 0.9754\n","Epoch 46/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9498 - val_loss: 0.9794\n","Epoch 47/500\n","31/31 [==============================] - 1s 47ms/step - loss: 0.9450 - val_loss: 0.9700\n","Epoch 48/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9431 - val_loss: 0.9686\n","Epoch 49/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9422 - val_loss: 0.9647\n","Epoch 50/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9391 - val_loss: 0.9615\n","Epoch 51/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9347 - val_loss: 0.9610\n","Epoch 52/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9328 - val_loss: 0.9569\n","Epoch 53/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9297 - val_loss: 0.9552\n","Epoch 54/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9293 - val_loss: 0.9580\n","Epoch 55/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9272 - val_loss: 0.9508\n","Epoch 56/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9240 - val_loss: 0.9479\n","Epoch 57/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9221 - val_loss: 0.9453\n","Epoch 58/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9209 - val_loss: 0.9443\n","Epoch 59/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9194 - val_loss: 0.9423\n","Epoch 60/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9185 - val_loss: 0.9404\n","Epoch 61/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9164 - val_loss: 0.9388\n","Epoch 62/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9153 - val_loss: 0.9364\n","Epoch 63/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9145 - val_loss: 0.9351\n","Epoch 64/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9135 - val_loss: 0.9347\n","Epoch 65/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9131 - val_loss: 0.9342\n","Epoch 66/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9121 - val_loss: 0.9316\n","Epoch 67/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9113 - val_loss: 0.9314\n","Epoch 68/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9104 - val_loss: 0.9300\n","Epoch 69/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9098 - val_loss: 0.9290\n","Epoch 70/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9098 - val_loss: 0.9283\n","Epoch 71/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9091 - val_loss: 0.9274\n","Epoch 72/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9090 - val_loss: 0.9283\n","Epoch 73/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9080 - val_loss: 0.9256\n","Epoch 74/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9077 - val_loss: 0.9252\n","Epoch 75/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9074 - val_loss: 0.9242\n","Epoch 76/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9070 - val_loss: 0.9242\n","Epoch 77/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9069 - val_loss: 0.9228\n","Epoch 78/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9062 - val_loss: 0.9234\n","Epoch 79/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9063 - val_loss: 0.9224\n","Epoch 80/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9059 - val_loss: 0.9214\n","Epoch 81/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9061 - val_loss: 0.9218\n","Epoch 82/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9055 - val_loss: 0.9197\n","Epoch 83/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9048 - val_loss: 0.9189\n","Epoch 84/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9046 - val_loss: 0.9205\n","Epoch 85/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9044 - val_loss: 0.9191\n","Epoch 86/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9040 - val_loss: 0.9180\n","Epoch 87/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9037 - val_loss: 0.9171\n","Epoch 88/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9036 - val_loss: 0.9179\n","Epoch 89/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9034 - val_loss: 0.9160\n","Epoch 90/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9032 - val_loss: 0.9160\n","Epoch 91/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9032 - val_loss: 0.9160\n","Epoch 92/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9029 - val_loss: 0.9152\n","Epoch 93/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9027 - val_loss: 0.9147\n","Epoch 94/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9024 - val_loss: 0.9149\n","Epoch 95/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9022 - val_loss: 0.9139\n","Epoch 96/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9020 - val_loss: 0.9141\n","Epoch 97/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9019 - val_loss: 0.9136\n","Epoch 98/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9018 - val_loss: 0.9138\n","Epoch 99/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9015 - val_loss: 0.9133\n","Epoch 100/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9017 - val_loss: 0.9125\n","Epoch 101/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9014 - val_loss: 0.9127\n","Epoch 102/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9014 - val_loss: 0.9122\n","Epoch 103/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9015 - val_loss: 0.9121\n","Epoch 104/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9010 - val_loss: 0.9133\n","Epoch 105/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9010 - val_loss: 0.9116\n","Epoch 106/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9009 - val_loss: 0.9104\n","Epoch 107/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9009 - val_loss: 0.9112\n","Epoch 108/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9008 - val_loss: 0.9107\n","Epoch 109/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9006 - val_loss: 0.9098\n","Epoch 110/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9003 - val_loss: 0.9099\n","Epoch 111/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9000 - val_loss: 0.9085\n","Epoch 112/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9003 - val_loss: 0.9092\n","Epoch 113/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9001 - val_loss: 0.9085\n","Epoch 114/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8999 - val_loss: 0.9082\n","Epoch 115/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8999 - val_loss: 0.9095\n","Epoch 116/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8996 - val_loss: 0.9086\n","Epoch 117/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8995 - val_loss: 0.9081\n","Epoch 118/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8995 - val_loss: 0.9084\n","Epoch 119/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8992 - val_loss: 0.9088\n","Epoch 120/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8993 - val_loss: 0.9074\n","Epoch 121/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8989 - val_loss: 0.9075\n","Epoch 122/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8990 - val_loss: 0.9078\n","Epoch 123/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8992 - val_loss: 0.9071\n","Epoch 124/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8989 - val_loss: 0.9067\n","Epoch 125/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8988 - val_loss: 0.9068\n","Epoch 126/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8985 - val_loss: 0.9067\n","Epoch 127/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8988 - val_loss: 0.9070\n","Epoch 128/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9004 - val_loss: 0.9067\n","Epoch 129/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8995 - val_loss: 0.9066\n","Epoch 130/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8989 - val_loss: 0.9057\n","Epoch 131/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8990 - val_loss: 0.9060\n","Epoch 132/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8991 - val_loss: 0.9059\n","Epoch 133/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8994 - val_loss: 0.9058\n","Epoch 134/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8987 - val_loss: 0.9055\n","Epoch 135/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8983 - val_loss: 0.9053\n","Epoch 136/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8983 - val_loss: 0.9044\n","Epoch 137/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8983 - val_loss: 0.9069\n","Epoch 138/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8982 - val_loss: 0.9051\n","Epoch 139/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8984 - val_loss: 0.9045\n","Epoch 140/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8979 - val_loss: 0.9049\n","Epoch 141/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8987 - val_loss: 0.9047\n","Epoch 142/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.8989 - val_loss: 0.9037\n","Epoch 143/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8979 - val_loss: 0.9055\n","Epoch 144/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8984 - val_loss: 0.9057\n","Epoch 145/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8982 - val_loss: 0.9039\n","Epoch 146/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8982 - val_loss: 0.9045\n","Epoch 147/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8986 - val_loss: 0.9032\n","Epoch 148/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8981 - val_loss: 0.9034\n","Epoch 149/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8976 - val_loss: 0.9049\n","Epoch 150/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8985 - val_loss: 0.9051\n","Epoch 151/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8981 - val_loss: 0.9047\n","Epoch 152/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8991 - val_loss: 0.9032\n","Epoch 153/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8976 - val_loss: 0.9024\n","Epoch 154/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8972 - val_loss: 0.9036\n","Epoch 155/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8971 - val_loss: 0.9041\n","Epoch 156/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8975 - val_loss: 0.9023\n","Epoch 157/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8975 - val_loss: 0.9035\n","Epoch 158/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8971 - val_loss: 0.9027\n","Epoch 159/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8971 - val_loss: 0.9025\n","Epoch 160/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8968 - val_loss: 0.9032\n","Epoch 161/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8969 - val_loss: 0.9019\n","Epoch 162/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8973 - val_loss: 0.9103\n","Epoch 163/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8988 - val_loss: 0.9017\n","Epoch 164/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8964 - val_loss: 0.9025\n","Epoch 165/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8965 - val_loss: 0.9021\n","Epoch 166/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8966 - val_loss: 0.9017\n","Epoch 167/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8965 - val_loss: 0.9024\n","Epoch 168/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8967 - val_loss: 0.9018\n","Epoch 169/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8966 - val_loss: 0.9012\n","Epoch 170/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8963 - val_loss: 0.9006\n","Epoch 171/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8970 - val_loss: 0.9013\n","Epoch 172/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8971 - val_loss: 0.9006\n","Epoch 173/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8963 - val_loss: 0.9035\n","Epoch 174/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8965 - val_loss: 0.9018\n","Epoch 175/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8960 - val_loss: 0.9008\n","Epoch 176/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8961 - val_loss: 0.9009\n","Epoch 177/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8958 - val_loss: 0.9003\n","Epoch 178/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8957 - val_loss: 0.9003\n","Epoch 179/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8962 - val_loss: 0.9017\n","Epoch 180/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8965 - val_loss: 0.9004\n","Epoch 181/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8960 - val_loss: 0.9011\n","Epoch 182/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8955 - val_loss: 0.8998\n","Epoch 183/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8952 - val_loss: 0.8995\n","Epoch 184/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8956 - val_loss: 0.8991\n","Epoch 185/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8953 - val_loss: 0.8998\n","Epoch 186/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8958 - val_loss: 0.9031\n","Epoch 187/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8954 - val_loss: 0.9001\n","Epoch 188/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8952 - val_loss: 0.8983\n","Epoch 189/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8952 - val_loss: 0.8993\n","Epoch 190/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8950 - val_loss: 0.8989\n","Epoch 191/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8955 - val_loss: 0.8988\n","Epoch 192/500\n","31/31 [==============================] - 2s 53ms/step - loss: 0.8953 - val_loss: 0.8985\n","34/34 [==============================] - 0s 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa62773373fa4ed18a5e1f758b2b14ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>██████▇▇▆▅▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>███████▇▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>191</td></tr><tr><td>epoch/learning_rate</td><td>0.0005</td></tr><tr><td>epoch/loss</td><td>0.89534</td></tr><tr><td>epoch/val_loss</td><td>0.89848</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">early_stopping_patience_50</strong> at: <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/k21sp125' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/k21sp125</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240214_122354-k21sp125/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240214_122640-goiabcg3</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/goiabcg3' target=\"_blank\">early_stopping_patience_50</a></strong> to <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/goiabcg3' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/goiabcg3</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model: \"model_12\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, 17162)]           0         \n","                                                                 \n"," dense_48 (Dense)            (None, 8000)              137304000 \n","                                                                 \n"," dense_49 (Dense)            (None, 1000)              8001000   \n","                                                                 \n"," dense_50 (Dense)            (None, 200)               200200    \n","                                                                 \n"," reshape_12 (Reshape)        (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_12 (Seq  (None, 200, 1)            129       \n"," SelfAttention)                                                  \n","                                                                 \n"," flatten_12 (Flatten)        (None, 200)               0         \n","                                                                 \n"," dense_51 (Dense)            (None, 10)                2010      \n","                                                                 \n"," dense_52 (Dense)            (None, 200)               2200      \n","                                                                 \n"," reshape_13 (Reshape)        (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_13 (Seq  (None, 200, 1)            129       \n"," SelfAttention)                                                  \n","                                                                 \n"," flatten_13 (Flatten)        (None, 200)               0         \n","                                                                 \n"," dense_53 (Dense)            (None, 1000)              201000    \n","                                                                 \n"," dense_54 (Dense)            (None, 8000)              8008000   \n","                                                                 \n"," dense_55 (Dense)            (None, 17162)             137313162 \n","                                                                 \n","=================================================================\n","Total params: 291031830 (1.08 GB)\n","Trainable params: 291031830 (1.08 GB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/500\n"," 6/31 [====>.........................] - ETA: 0s - loss: 1.5070"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0106s vs `on_train_batch_end` time: 0.0118s). Check your callbacks.\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 7s 78ms/step - loss: 1.1177 - val_loss: 1.0183\n","Epoch 2/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9978 - val_loss: 1.0170\n","Epoch 3/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9974 - val_loss: 1.0170\n","Epoch 4/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9973 - val_loss: 1.0169\n","Epoch 5/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9973 - val_loss: 1.0170\n","Epoch 6/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9972 - val_loss: 1.0171\n","Epoch 7/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9972 - val_loss: 1.0171\n","Epoch 8/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9972 - val_loss: 1.0171\n","Epoch 9/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9972 - val_loss: 1.0172\n","Epoch 10/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9971 - val_loss: 1.0172\n","Epoch 11/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9971 - val_loss: 1.0172\n","Epoch 12/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9970 - val_loss: 1.0173\n","Epoch 13/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9970 - val_loss: 1.0174\n","Epoch 14/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9969 - val_loss: 1.0174\n","Epoch 15/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9969 - val_loss: 1.0175\n","Epoch 16/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9968 - val_loss: 1.0176\n","Epoch 17/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9966 - val_loss: 1.0176\n","Epoch 18/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9964 - val_loss: 1.0178\n","Epoch 19/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9961 - val_loss: 1.0179\n","Epoch 20/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9957 - val_loss: 1.0181\n","Epoch 21/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9952 - val_loss: 1.0173\n","Epoch 22/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9943 - val_loss: 1.0171\n","Epoch 23/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9933 - val_loss: 1.0169\n","Epoch 24/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9921 - val_loss: 1.0154\n","Epoch 25/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9907 - val_loss: 1.0142\n","Epoch 26/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9889 - val_loss: 1.0135\n","Epoch 27/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9868 - val_loss: 1.0122\n","Epoch 28/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9845 - val_loss: 1.0108\n","Epoch 29/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9819 - val_loss: 1.0061\n","Epoch 30/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9791 - val_loss: 1.0041\n","Epoch 31/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9759 - val_loss: 1.0008\n","Epoch 32/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9729 - val_loss: 0.9973\n","Epoch 33/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9693 - val_loss: 0.9934\n","Epoch 34/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9657 - val_loss: 0.9901\n","Epoch 35/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9625 - val_loss: 0.9872\n","Epoch 36/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9594 - val_loss: 0.9851\n","Epoch 37/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9570 - val_loss: 0.9814\n","Epoch 38/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9536 - val_loss: 0.9778\n","Epoch 39/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9511 - val_loss: 0.9750\n","Epoch 40/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9485 - val_loss: 0.9722\n","Epoch 41/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9462 - val_loss: 0.9693\n","Epoch 42/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9442 - val_loss: 0.9672\n","Epoch 43/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9422 - val_loss: 0.9649\n","Epoch 44/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9401 - val_loss: 0.9633\n","Epoch 45/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9385 - val_loss: 0.9623\n","Epoch 46/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9370 - val_loss: 0.9597\n","Epoch 47/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9355 - val_loss: 0.9586\n","Epoch 48/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9343 - val_loss: 0.9559\n","Epoch 49/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9329 - val_loss: 0.9543\n","Epoch 50/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9319 - val_loss: 0.9530\n","Epoch 51/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9303 - val_loss: 0.9518\n","Epoch 52/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9292 - val_loss: 0.9526\n","Epoch 53/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9283 - val_loss: 0.9498\n","Epoch 54/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9272 - val_loss: 0.9484\n","Epoch 55/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9263 - val_loss: 0.9477\n","Epoch 56/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9258 - val_loss: 0.9465\n","Epoch 57/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9247 - val_loss: 0.9456\n","Epoch 58/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9240 - val_loss: 0.9454\n","Epoch 59/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9235 - val_loss: 0.9447\n","Epoch 60/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9228 - val_loss: 0.9429\n","Epoch 61/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9217 - val_loss: 0.9426\n","Epoch 62/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9214 - val_loss: 0.9421\n","Epoch 63/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9208 - val_loss: 0.9411\n","Epoch 64/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9201 - val_loss: 0.9403\n","Epoch 65/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9194 - val_loss: 0.9402\n","Epoch 66/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9189 - val_loss: 0.9394\n","Epoch 67/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9184 - val_loss: 0.9385\n","Epoch 68/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9177 - val_loss: 0.9371\n","Epoch 69/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9171 - val_loss: 0.9374\n","Epoch 70/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9167 - val_loss: 0.9363\n","Epoch 71/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9160 - val_loss: 0.9360\n","Epoch 72/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9157 - val_loss: 0.9356\n","Epoch 73/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9153 - val_loss: 0.9348\n","Epoch 74/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9147 - val_loss: 0.9344\n","Epoch 75/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9143 - val_loss: 0.9343\n","Epoch 76/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9139 - val_loss: 0.9330\n","Epoch 77/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9137 - val_loss: 0.9330\n","Epoch 78/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9136 - val_loss: 0.9326\n","Epoch 79/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9130 - val_loss: 0.9324\n","Epoch 80/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9127 - val_loss: 0.9316\n","Epoch 81/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9127 - val_loss: 0.9312\n","Epoch 82/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9120 - val_loss: 0.9306\n","Epoch 83/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9116 - val_loss: 0.9300\n","Epoch 84/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9111 - val_loss: 0.9294\n","Epoch 85/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9111 - val_loss: 0.9296\n","Epoch 86/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9107 - val_loss: 0.9289\n","Epoch 87/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9103 - val_loss: 0.9288\n","Epoch 88/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9099 - val_loss: 0.9285\n","Epoch 89/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9096 - val_loss: 0.9281\n","Epoch 90/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9096 - val_loss: 0.9272\n","Epoch 91/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9092 - val_loss: 0.9270\n","Epoch 92/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9092 - val_loss: 0.9274\n","Epoch 93/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9086 - val_loss: 0.9264\n","Epoch 94/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9084 - val_loss: 0.9261\n","Epoch 95/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9084 - val_loss: 0.9259\n","Epoch 96/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9079 - val_loss: 0.9252\n","Epoch 97/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9077 - val_loss: 0.9255\n","Epoch 98/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9075 - val_loss: 0.9247\n","Epoch 99/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9072 - val_loss: 0.9246\n","Epoch 100/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9070 - val_loss: 0.9244\n","Epoch 101/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9072 - val_loss: 0.9238\n","Epoch 102/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9066 - val_loss: 0.9241\n","Epoch 103/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9066 - val_loss: 0.9234\n","Epoch 104/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9065 - val_loss: 0.9235\n","Epoch 105/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9062 - val_loss: 0.9232\n","Epoch 106/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9061 - val_loss: 0.9225\n","Epoch 107/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9059 - val_loss: 0.9224\n","Epoch 108/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9057 - val_loss: 0.9222\n","Epoch 109/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9052 - val_loss: 0.9214\n","Epoch 110/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9053 - val_loss: 0.9213\n","Epoch 111/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9050 - val_loss: 0.9215\n","Epoch 112/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9047 - val_loss: 0.9219\n","Epoch 113/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9053 - val_loss: 0.9222\n","Epoch 114/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9056 - val_loss: 0.9210\n","Epoch 115/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9056 - val_loss: 0.9224\n","Epoch 116/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9046 - val_loss: 0.9204\n","Epoch 117/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9043 - val_loss: 0.9202\n","Epoch 118/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9041 - val_loss: 0.9195\n","Epoch 119/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9040 - val_loss: 0.9197\n","Epoch 120/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9041 - val_loss: 0.9196\n","Epoch 121/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9038 - val_loss: 0.9188\n","Epoch 122/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9036 - val_loss: 0.9192\n","Epoch 123/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9033 - val_loss: 0.9189\n","Epoch 124/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9033 - val_loss: 0.9188\n","Epoch 125/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9031 - val_loss: 0.9181\n","Epoch 126/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9030 - val_loss: 0.9179\n","Epoch 127/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9028 - val_loss: 0.9180\n","Epoch 128/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9028 - val_loss: 0.9179\n","Epoch 129/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9026 - val_loss: 0.9182\n","Epoch 130/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9025 - val_loss: 0.9176\n","Epoch 131/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9024 - val_loss: 0.9175\n","Epoch 132/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9022 - val_loss: 0.9170\n","Epoch 133/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9022 - val_loss: 0.9188\n","Epoch 134/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9028 - val_loss: 0.9171\n","Epoch 135/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9025 - val_loss: 0.9168\n","Epoch 136/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9019 - val_loss: 0.9165\n","Epoch 137/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9018 - val_loss: 0.9164\n","Epoch 138/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9017 - val_loss: 0.9167\n","Epoch 139/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9015 - val_loss: 0.9161\n","Epoch 140/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9015 - val_loss: 0.9161\n","Epoch 141/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9016 - val_loss: 0.9167\n","Epoch 142/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9016 - val_loss: 0.9158\n","Epoch 143/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9014 - val_loss: 0.9150\n","Epoch 144/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9012 - val_loss: 0.9152\n","Epoch 145/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9010 - val_loss: 0.9162\n","Epoch 146/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9008 - val_loss: 0.9150\n","Epoch 147/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9007 - val_loss: 0.9148\n","Epoch 148/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9005 - val_loss: 0.9148\n","Epoch 149/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9005 - val_loss: 0.9146\n","Epoch 150/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9005 - val_loss: 0.9147\n","Epoch 151/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9006 - val_loss: 0.9150\n","Epoch 152/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9004 - val_loss: 0.9141\n","Epoch 153/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9003 - val_loss: 0.9146\n","Epoch 154/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9006 - val_loss: 0.9138\n","Epoch 155/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9004 - val_loss: 0.9145\n","Epoch 156/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9003 - val_loss: 0.9132\n","Epoch 157/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8998 - val_loss: 0.9132\n","Epoch 158/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8999 - val_loss: 0.9132\n","Epoch 159/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9001 - val_loss: 0.9131\n","Epoch 160/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9001 - val_loss: 0.9132\n","Epoch 161/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8995 - val_loss: 0.9124\n","Epoch 162/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8996 - val_loss: 0.9129\n","Epoch 163/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8995 - val_loss: 0.9127\n","Epoch 164/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8993 - val_loss: 0.9124\n","Epoch 165/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8992 - val_loss: 0.9117\n","Epoch 166/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8994 - val_loss: 0.9137\n","Epoch 167/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8996 - val_loss: 0.9122\n","Epoch 168/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8997 - val_loss: 0.9130\n","Epoch 169/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8996 - val_loss: 0.9123\n","Epoch 170/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8996 - val_loss: 0.9129\n","Epoch 171/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8991 - val_loss: 0.9125\n","Epoch 172/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8991 - val_loss: 0.9120\n","Epoch 173/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8988 - val_loss: 0.9112\n","Epoch 174/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8989 - val_loss: 0.9115\n","Epoch 175/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8989 - val_loss: 0.9117\n","Epoch 176/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8987 - val_loss: 0.9111\n","Epoch 177/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8988 - val_loss: 0.9113\n","Epoch 178/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8985 - val_loss: 0.9115\n","Epoch 179/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8986 - val_loss: 0.9108\n","Epoch 180/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8986 - val_loss: 0.9114\n","Epoch 181/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8983 - val_loss: 0.9113\n","Epoch 182/500\n","31/31 [==============================] - 2s 53ms/step - loss: 0.8984 - val_loss: 0.9112\n","34/34 [==============================] - 0s 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a39ee3237ff4792b4de24211fe46f86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>██████▇▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>███████▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>181</td></tr><tr><td>epoch/learning_rate</td><td>0.0005</td></tr><tr><td>epoch/loss</td><td>0.89839</td></tr><tr><td>epoch/val_loss</td><td>0.9112</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">early_stopping_patience_50</strong> at: <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/goiabcg3' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/goiabcg3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240214_122640-goiabcg3/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240214_122920-bcjrnlwv</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/bcjrnlwv' target=\"_blank\">early_stopping_patience_50</a></strong> to <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/bcjrnlwv' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/bcjrnlwv</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model: \"model_14\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 17162)]           0         \n","                                                                 \n"," dense_56 (Dense)            (None, 8000)              137304000 \n","                                                                 \n"," dense_57 (Dense)            (None, 1000)              8001000   \n","                                                                 \n"," dense_58 (Dense)            (None, 200)               200200    \n","                                                                 \n"," reshape_14 (Reshape)        (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_14 (Seq  (None, 200, 1)            129       \n"," SelfAttention)                                                  \n","                                                                 \n"," flatten_14 (Flatten)        (None, 200)               0         \n","                                                                 \n"," dense_59 (Dense)            (None, 10)                2010      \n","                                                                 \n"," dense_60 (Dense)            (None, 200)               2200      \n","                                                                 \n"," reshape_15 (Reshape)        (None, 200, 1)            0         \n","                                                                 \n"," seq_self_attention_15 (Seq  (None, 200, 1)            129       \n"," SelfAttention)                                                  \n","                                                                 \n"," flatten_15 (Flatten)        (None, 200)               0         \n","                                                                 \n"," dense_61 (Dense)            (None, 1000)              201000    \n","                                                                 \n"," dense_62 (Dense)            (None, 8000)              8008000   \n","                                                                 \n"," dense_63 (Dense)            (None, 17162)             137313162 \n","                                                                 \n","=================================================================\n","Total params: 291031830 (1.08 GB)\n","Trainable params: 291031830 (1.08 GB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/500\n"," 5/31 [===>..........................] - ETA: 0s - loss: 1.6110"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0108s vs `on_train_batch_end` time: 0.0118s). Check your callbacks.\n"]},{"output_type":"stream","name":"stdout","text":["31/31 [==============================] - 6s 79ms/step - loss: 1.1277 - val_loss: 0.9758\n","Epoch 2/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0023 - val_loss: 0.9749\n","Epoch 3/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0020 - val_loss: 0.9749\n","Epoch 4/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0020 - val_loss: 0.9750\n","Epoch 5/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0019 - val_loss: 0.9752\n","Epoch 6/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0019 - val_loss: 0.9752\n","Epoch 7/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0018 - val_loss: 0.9753\n","Epoch 8/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0017 - val_loss: 0.9754\n","Epoch 9/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0017 - val_loss: 0.9755\n","Epoch 10/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0016 - val_loss: 0.9756\n","Epoch 11/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0016 - val_loss: 0.9757\n","Epoch 12/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0015 - val_loss: 0.9758\n","Epoch 13/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0015 - val_loss: 0.9758\n","Epoch 14/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0013 - val_loss: 0.9759\n","Epoch 15/500\n","31/31 [==============================] - 1s 24ms/step - loss: 1.0011 - val_loss: 0.9761\n","Epoch 16/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0009 - val_loss: 0.9759\n","Epoch 17/500\n","31/31 [==============================] - 1s 25ms/step - loss: 1.0005 - val_loss: 0.9760\n","Epoch 18/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9999 - val_loss: 0.9759\n","Epoch 19/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9993 - val_loss: 0.9760\n","Epoch 20/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9988 - val_loss: 0.9752\n","Epoch 21/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9977 - val_loss: 0.9750\n","Epoch 22/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9970 - val_loss: 0.9752\n","Epoch 23/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9959 - val_loss: 0.9736\n","Epoch 24/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9947 - val_loss: 0.9717\n","Epoch 25/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9938 - val_loss: 0.9727\n","Epoch 26/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9925 - val_loss: 0.9703\n","Epoch 27/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9906 - val_loss: 0.9718\n","Epoch 28/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9891 - val_loss: 0.9698\n","Epoch 29/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9868 - val_loss: 0.9659\n","Epoch 30/500\n","31/31 [==============================] - 1s 45ms/step - loss: 0.9850 - val_loss: 0.9644\n","Epoch 31/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9828 - val_loss: 0.9625\n","Epoch 32/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9802 - val_loss: 0.9620\n","Epoch 33/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9773 - val_loss: 0.9594\n","Epoch 34/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9753 - val_loss: 0.9583\n","Epoch 35/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9717 - val_loss: 0.9611\n","Epoch 36/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9705 - val_loss: 0.9535\n","Epoch 37/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9683 - val_loss: 0.9527\n","Epoch 38/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9635 - val_loss: 0.9536\n","Epoch 39/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9615 - val_loss: 0.9475\n","Epoch 40/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9573 - val_loss: 0.9480\n","Epoch 41/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9542 - val_loss: 0.9443\n","Epoch 42/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9520 - val_loss: 0.9435\n","Epoch 43/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9486 - val_loss: 0.9390\n","Epoch 44/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9459 - val_loss: 0.9372\n","Epoch 45/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9434 - val_loss: 0.9353\n","Epoch 46/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9407 - val_loss: 0.9346\n","Epoch 47/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9398 - val_loss: 0.9328\n","Epoch 48/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9378 - val_loss: 0.9299\n","Epoch 49/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9372 - val_loss: 0.9295\n","Epoch 50/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9346 - val_loss: 0.9280\n","Epoch 51/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9331 - val_loss: 0.9294\n","Epoch 52/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9291 - val_loss: 0.9250\n","Epoch 53/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9283 - val_loss: 0.9245\n","Epoch 54/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9250 - val_loss: 0.9223\n","Epoch 55/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9231 - val_loss: 0.9217\n","Epoch 56/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9214 - val_loss: 0.9212\n","Epoch 57/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9205 - val_loss: 0.9204\n","Epoch 58/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9190 - val_loss: 0.9201\n","Epoch 59/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9179 - val_loss: 0.9186\n","Epoch 60/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9164 - val_loss: 0.9178\n","Epoch 61/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9165 - val_loss: 0.9211\n","Epoch 62/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9146 - val_loss: 0.9164\n","Epoch 63/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9134 - val_loss: 0.9164\n","Epoch 64/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9125 - val_loss: 0.9164\n","Epoch 65/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9115 - val_loss: 0.9167\n","Epoch 66/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9111 - val_loss: 0.9146\n","Epoch 67/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9120 - val_loss: 0.9168\n","Epoch 68/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9098 - val_loss: 0.9140\n","Epoch 69/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9087 - val_loss: 0.9139\n","Epoch 70/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9084 - val_loss: 0.9152\n","Epoch 71/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9092 - val_loss: 0.9132\n","Epoch 72/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9075 - val_loss: 0.9135\n","Epoch 73/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9064 - val_loss: 0.9129\n","Epoch 74/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9060 - val_loss: 0.9140\n","Epoch 75/500\n","31/31 [==============================] - 1s 46ms/step - loss: 0.9054 - val_loss: 0.9123\n","Epoch 76/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9049 - val_loss: 0.9126\n","Epoch 77/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9048 - val_loss: 0.9123\n","Epoch 78/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9043 - val_loss: 0.9115\n","Epoch 79/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9042 - val_loss: 0.9113\n","Epoch 80/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9040 - val_loss: 0.9111\n","Epoch 81/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9031 - val_loss: 0.9114\n","Epoch 82/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9029 - val_loss: 0.9129\n","Epoch 83/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9027 - val_loss: 0.9112\n","Epoch 84/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9023 - val_loss: 0.9118\n","Epoch 85/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9022 - val_loss: 0.9112\n","Epoch 86/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9023 - val_loss: 0.9106\n","Epoch 87/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9015 - val_loss: 0.9127\n","Epoch 88/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9017 - val_loss: 0.9110\n","Epoch 89/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9016 - val_loss: 0.9108\n","Epoch 90/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9016 - val_loss: 0.9106\n","Epoch 91/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9006 - val_loss: 0.9110\n","Epoch 92/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.9003 - val_loss: 0.9106\n","Epoch 93/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9002 - val_loss: 0.9100\n","Epoch 94/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8997 - val_loss: 0.9097\n","Epoch 95/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8998 - val_loss: 0.9100\n","Epoch 96/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.9002 - val_loss: 0.9100\n","Epoch 97/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8993 - val_loss: 0.9101\n","Epoch 98/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8993 - val_loss: 0.9101\n","Epoch 99/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8990 - val_loss: 0.9097\n","Epoch 100/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8989 - val_loss: 0.9093\n","Epoch 101/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8985 - val_loss: 0.9089\n","Epoch 102/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8985 - val_loss: 0.9092\n","Epoch 103/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8982 - val_loss: 0.9095\n","Epoch 104/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8990 - val_loss: 0.9095\n","Epoch 105/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8984 - val_loss: 0.9092\n","Epoch 106/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8982 - val_loss: 0.9091\n","Epoch 107/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8979 - val_loss: 0.9090\n","Epoch 108/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8979 - val_loss: 0.9096\n","Epoch 109/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8977 - val_loss: 0.9088\n","Epoch 110/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8980 - val_loss: 0.9089\n","Epoch 111/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8976 - val_loss: 0.9086\n","Epoch 112/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8974 - val_loss: 0.9091\n","Epoch 113/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8971 - val_loss: 0.9082\n","Epoch 114/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8976 - val_loss: 0.9085\n","Epoch 115/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8974 - val_loss: 0.9091\n","Epoch 116/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8969 - val_loss: 0.9082\n","Epoch 117/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8969 - val_loss: 0.9081\n","Epoch 118/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8969 - val_loss: 0.9087\n","Epoch 119/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8966 - val_loss: 0.9087\n","Epoch 120/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8964 - val_loss: 0.9086\n","Epoch 121/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8965 - val_loss: 0.9092\n","Epoch 122/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8962 - val_loss: 0.9083\n","Epoch 123/500\n","31/31 [==============================] - 1s 25ms/step - loss: 0.8961 - val_loss: 0.9081\n","Epoch 124/500\n","31/31 [==============================] - 1s 24ms/step - loss: 0.8963 - val_loss: 0.9149\n","Epoch 125/500\n","31/31 [==============================] - 2s 53ms/step - loss: 0.8982 - val_loss: 0.9094\n","34/34 [==============================] - 0s 2ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4693c213b33d4c20bc75a428211e7d75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▄▄▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>████████▇▇▇▆▅▅▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/epoch</td><td>124</td></tr><tr><td>epoch/learning_rate</td><td>0.0005</td></tr><tr><td>epoch/loss</td><td>0.89817</td></tr><tr><td>epoch/val_loss</td><td>0.90944</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">early_stopping_patience_50</strong> at: <a href='https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/bcjrnlwv' target=\"_blank\">https://wandb.ai/cosybio-compsysmed/Attention_AE_fitting/runs/bcjrnlwv</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240214_122920-bcjrnlwv/logs</code>"]},"metadata":{}}],"source":["encoding1_dim = 8000\n","encoding2_dim = 1000\n","encoding3_dim = 200\n","middle_dim = 10\n","dims = [encoding1_dim, encoding2_dim, encoding3_dim, middle_dim]\n","\n","\n","for i in range(3, 11):\n","    # initialize a new run (<=> single unit of computation)\n","    run = wandb.init(project=\"Attention_AE_fitting\",\n","                     # Set the project where this run will be logged\n","                     name=f\"early_stopping_patience_50\",  # We pass a run name otherwise it’ll be randomly assigned\n","                     # Track hyperparameters and run metadata\n","                     config={\n","                         \"optimizer\": \"adam\",\n","                         \"loss\": \"mse\",\n","                         \"training_set\": \"BRCA\",\n","                         \"validation split\": 0.1,\n","                         \"test_set\": \"none\",\n","                         \"batch_size\": 32,\n","                         \"encoding_layers\": 3,\n","                         \"activation_functions\": \"sigmoid, sigmoid, sigmoid, identity\",\n","                         \"self-attention layers\": \"1 in encoder & decoder\"\n","                     })\n","\n","    ae = AE(input_data, dims)\n","    ae.autoencoder.summary()\n","    ae.train()\n","\n","    # Save embedded encodings\n","    encoded_factors = ae.predict(input_data)\n","    if not os.path.exists(\"{p}/Attention_AE_EM_{i}.txt\".format(p=result_path, i=i)):\n","        os.mknod(\"{p}/Attention_AE_EM_{i}.txt\".format(p=result_path, i=i))\n","    np.savetxt(\"{p}/Attention_AE_EM_{i}.txt\".format(p=result_path, i=i), encoded_factors)\n","\n","    # Mark the run as finished\n","    wandb.finish()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4a5abe10049845a7af5a0cab3924b3a6":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_77fc5313a5c74e23ba996e56a16cd569","IPY_MODEL_413218635fda425abd9973a4d2dd977e"],"layout":"IPY_MODEL_1b2810cce0374abaa89c483b496d8326"}},"77fc5313a5c74e23ba996e56a16cd569":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74d50636d20e4a378f8fe2b82405b267","placeholder":"​","style":"IPY_MODEL_31b50d33ede04b688f7ef9cc06f79c99","value":"0.021 MB of 0.021 MB uploaded\r"}},"413218635fda425abd9973a4d2dd977e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d13c0f7a472540cdbe40a4e1e08fac54","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64a11b7adc2149fd9624a929961f8c49","value":1}},"1b2810cce0374abaa89c483b496d8326":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74d50636d20e4a378f8fe2b82405b267":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31b50d33ede04b688f7ef9cc06f79c99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d13c0f7a472540cdbe40a4e1e08fac54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64a11b7adc2149fd9624a929961f8c49":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f1ab337d4d94bd593921b689ff34bb7":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_67e0bcb2bf4c4f60b46a2895fd8bb742","IPY_MODEL_d3a4e09cda804c979a5145b1c92ef98d"],"layout":"IPY_MODEL_6496e450d7f34d0492232db68255f0d0"}},"67e0bcb2bf4c4f60b46a2895fd8bb742":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c83ad2d9536a4549ad62a5da4ca22d38","placeholder":"​","style":"IPY_MODEL_ba8fcc4e0e06471e994c3b77d6b2bff5","value":"0.020 MB of 0.020 MB uploaded\r"}},"d3a4e09cda804c979a5145b1c92ef98d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9404b0dd4c7844d8a15a84ba45838431","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f394af8cb0d14e1a818d22f15e8f9677","value":1}},"6496e450d7f34d0492232db68255f0d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c83ad2d9536a4549ad62a5da4ca22d38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba8fcc4e0e06471e994c3b77d6b2bff5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9404b0dd4c7844d8a15a84ba45838431":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f394af8cb0d14e1a818d22f15e8f9677":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69776819526d445dac35553c3d095d51":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_6e463566688b434082995cadbf07a9a1","IPY_MODEL_8f183b0ec16f4cb9bd36161d872c5cf7"],"layout":"IPY_MODEL_7909d9dc4755458293e15a8c0b75e40a"}},"6e463566688b434082995cadbf07a9a1":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e12fcf51748c441481973edb5425a6ad","placeholder":"​","style":"IPY_MODEL_38b6d5ea99d047fb8aeb36a4327f74f0","value":"0.021 MB of 0.021 MB uploaded\r"}},"8f183b0ec16f4cb9bd36161d872c5cf7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c5e076491784412963d74f86c24da1e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68610d8c1b364d9496a8a4bcf06c8a9a","value":1}},"7909d9dc4755458293e15a8c0b75e40a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e12fcf51748c441481973edb5425a6ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38b6d5ea99d047fb8aeb36a4327f74f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c5e076491784412963d74f86c24da1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68610d8c1b364d9496a8a4bcf06c8a9a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ddecf9b347647f99d4d52524d7dd9c9":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_52c14fec408142feb7e6dc85d3eded93","IPY_MODEL_266e89f34b2541e096fc21dde118e9f0"],"layout":"IPY_MODEL_8fa0affb3f24437f91168fd58ef7f44b"}},"52c14fec408142feb7e6dc85d3eded93":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00f349b1a74e497998f4b73b4cf693cf","placeholder":"​","style":"IPY_MODEL_f04c1ab0d19743a284613e9db43acc98","value":"0.021 MB of 0.021 MB uploaded\r"}},"266e89f34b2541e096fc21dde118e9f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac8563cc8f4446a4b15083474d84e7e8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c76f2c77ef24a3bbda2a12ed1d92fe0","value":1}},"8fa0affb3f24437f91168fd58ef7f44b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00f349b1a74e497998f4b73b4cf693cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f04c1ab0d19743a284613e9db43acc98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac8563cc8f4446a4b15083474d84e7e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c76f2c77ef24a3bbda2a12ed1d92fe0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f7d78c6fba449838a29429bf5c865d8":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_880877a1923a4ff3ae91e27f4daf9ba7","IPY_MODEL_984d149559b24aebad9e1ed2c2aa736c"],"layout":"IPY_MODEL_b7a082541f1e4be6bce3acd4f3d5f07b"}},"880877a1923a4ff3ae91e27f4daf9ba7":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_616ab1eb761d41ab8ecc79d80cebeb70","placeholder":"​","style":"IPY_MODEL_c8e66f1855ee4c06af20f81d641b817a","value":"0.022 MB of 0.022 MB uploaded\r"}},"984d149559b24aebad9e1ed2c2aa736c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5951f5551a5942fb8023a9c4df946594","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b014897f2a44ced8559897a4c43edc5","value":1}},"b7a082541f1e4be6bce3acd4f3d5f07b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"616ab1eb761d41ab8ecc79d80cebeb70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8e66f1855ee4c06af20f81d641b817a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5951f5551a5942fb8023a9c4df946594":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b014897f2a44ced8559897a4c43edc5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa62773373fa4ed18a5e1f758b2b14ca":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_a7d53d930163452d88b4fdacc9328f7f","IPY_MODEL_05f34536f54244b7bce8bbe2a5a2b045"],"layout":"IPY_MODEL_2cfc19e88a294b619e94582205a614d2"}},"a7d53d930163452d88b4fdacc9328f7f":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f15f77ca3b7b45f7aa57c50fae41f964","placeholder":"​","style":"IPY_MODEL_01bba803a0e24790b396dbe81044f906","value":"0.023 MB of 0.023 MB uploaded\r"}},"05f34536f54244b7bce8bbe2a5a2b045":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_dddc267f65fb4fc4ad0f17173a98fc89","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cad5e43c42554a9c89ccc66efb8d2448","value":1}},"2cfc19e88a294b619e94582205a614d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f15f77ca3b7b45f7aa57c50fae41f964":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01bba803a0e24790b396dbe81044f906":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dddc267f65fb4fc4ad0f17173a98fc89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cad5e43c42554a9c89ccc66efb8d2448":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a39ee3237ff4792b4de24211fe46f86":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_5ad675b27d17451d9233e8d1ba09fad2","IPY_MODEL_833a9c94f65541a79f8f74d579863485"],"layout":"IPY_MODEL_5c94aaf7663c41f7a37552341be63a98"}},"5ad675b27d17451d9233e8d1ba09fad2":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8c51aeb7d2d4876bbae835c3afb5216","placeholder":"​","style":"IPY_MODEL_0b8eb8bb5a6c436f947f999ceb53d984","value":"0.022 MB of 0.022 MB uploaded\r"}},"833a9c94f65541a79f8f74d579863485":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bf77b4ca2b945e7a222b34d402aee5d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18b856029c0848139973f21434f5f7a6","value":1}},"5c94aaf7663c41f7a37552341be63a98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8c51aeb7d2d4876bbae835c3afb5216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b8eb8bb5a6c436f947f999ceb53d984":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bf77b4ca2b945e7a222b34d402aee5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18b856029c0848139973f21434f5f7a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4693c213b33d4c20bc75a428211e7d75":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_f5eb938f552c4ac9b33765a19a70ebb4","IPY_MODEL_dfafe3d53cff4c269ff29bb0eca68cce"],"layout":"IPY_MODEL_61ec2ed81b064c628d4ea33b11088777"}},"f5eb938f552c4ac9b33765a19a70ebb4":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77d2897b14c74cb8b8888b3951cda99d","placeholder":"​","style":"IPY_MODEL_0712ee4c32c44edab77413b35f3d3f33","value":"0.020 MB of 0.020 MB uploaded\r"}},"dfafe3d53cff4c269ff29bb0eca68cce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a022aafd441940e68806b49996f48eab","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e22624203e26469fbdfcc7da446425d4","value":1}},"61ec2ed81b064c628d4ea33b11088777":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77d2897b14c74cb8b8888b3951cda99d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0712ee4c32c44edab77413b35f3d3f33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a022aafd441940e68806b49996f48eab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e22624203e26469fbdfcc7da446425d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}